{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import datetime as dt\n",
    "from sklearn import linear_model\n",
    "import operator\n",
    "import sklearn_pandas\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn_pandas import CategoricalImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84603, 144)\n"
     ]
    }
   ],
   "source": [
    "liver_df = pd.read_csv('liver_data_inf560.csv')\n",
    "print (liver_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows where age<18\n",
    "liver_df = liver_df.loc[liver_df['AGE'] >=18]\n",
    "\n",
    "#remove rows where ptime<gtime\n",
    "liver_df = liver_df.loc[liver_df['GTIME'] < liver_df['PTIME']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_transplant_features=['ACUTE_REJ_EPI','GRF_STAT','GTIME','PTIME','PSTATUS','PX_STAT']\n",
    "liver_df.drop(post_transplant_features, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39162, 68)\n",
      "(39162, 70)\n"
     ]
    }
   ],
   "source": [
    "X_cf = liver_df.select_dtypes(include=['object'])\n",
    "print (X_cf.shape)\n",
    "X_ncf = liver_df.select_dtypes(exclude=['object'])\n",
    "print (X_ncf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Null Values for Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cat = CategoricalImputer()\n",
    "X_cf = pd.DataFrame(imp_cat.fit_transform(np.array(X_cf)),columns = X_cf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching score for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.409352104886752 0.1665380663371406\n",
      "0.06282071537955335 0.8020919814141305\n",
      "0.44958680287655994 0.929818855434263\n",
      "4.519254637301104 0.21057923438654064\n",
      "6.57304278863462 0.4746439448790196\n",
      "0.06943263592455594 0.7921646591920652\n",
      "5.493224660679154 0.2403256795930887\n",
      "6.814478096652416 0.23480747664855348\n"
     ]
    }
   ],
   "source": [
    "X_cf_gstatus0 = liver_df.loc[liver_df['GSTATUS'] == 0]\n",
    "X_cf_gstatus1 = liver_df.loc[liver_df['GSTATUS'] == 1]\n",
    "\n",
    "#Recipient features\n",
    "tab = pd.crosstab(liver_df['ABO'], liver_df['GSTATUS'])\n",
    "a,b,c,d = chi2_contingency(tab.values)\n",
    "print(a,b)\n",
    "\n",
    "tab = pd.crosstab(liver_df['GENDER'], liver_df['GSTATUS'])\n",
    "a,b,c,d = chi2_contingency(tab.values)\n",
    "print(a,b)\n",
    "\n",
    "tab = pd.crosstab(liver_df['HBV_CORE'], liver_df['GSTATUS'])\n",
    "a,b,c,d = chi2_contingency(tab.values)\n",
    "print(a,b)\n",
    "\n",
    "tab = pd.crosstab(liver_df['HBV_SUR_ANTIGEN'], liver_df['GSTATUS'])\n",
    "a,b,c,d = chi2_contingency(tab.values)\n",
    "print(a,b)\n",
    "\n",
    "\n",
    "#Donor features\n",
    "tab = pd.crosstab(liver_df['ABO_DON'], liver_df['GSTATUS'])\n",
    "a,b,c,d = chi2_contingency(tab.values)\n",
    "print(a,b)\n",
    "\n",
    "tab = pd.crosstab(liver_df['GENDER_DON'], liver_df['GSTATUS'])\n",
    "a,b,c,d = chi2_contingency(tab.values)\n",
    "print(a,b)\n",
    "\n",
    "tab = pd.crosstab(liver_df['HBV_CORE_DON'], liver_df['GSTATUS'])\n",
    "a,b,c,d = chi2_contingency(tab.values)\n",
    "print(a,b)\n",
    "\n",
    "tab = pd.crosstab(liver_df['HBV_SUR_ANTIGEN_DON'], liver_df['GSTATUS'])\n",
    "a,b,c,d = chi2_contingency(tab.values)\n",
    "print(a,b)\n",
    "\n",
    "\n",
    "weight_cat_norm = [1,0.0183,0.3499,0.6673]\n",
    "recipient_class_gstatus0 = np.array(X_cf_gstatus0[['ABO','GENDER','HBV_CORE','HBV_SUR_ANTIGEN']])\n",
    "recipient_class_gstatus1 = np.array(X_cf_gstatus1[['ABO','GENDER','HBV_CORE','HBV_SUR_ANTIGEN']])\n",
    "\n",
    "donor_class_gstatus0 = np.array(X_cf_gstatus0[['ABO_DON','GENDER_DON','HBV_CORE_DON','HBV_SUR_ANTIGEN_DON']])\n",
    "donor_class_gstatus1 = np.array(X_cf_gstatus1[['ABO_DON','GENDER_DON','HBV_CORE_DON','HBV_SUR_ANTIGEN_DON']])\n",
    "\n",
    "cat_weights_gstatus0 = []\n",
    "cat_weights_gstatus1 = []\n",
    "for i in range(len(recipient_class_gstatus0)):\n",
    "    weights = 0\n",
    "    for j in range(len(recipient_class_gstatus0[i])):\n",
    "        if recipient_class_gstatus0[i][j] == donor_class_gstatus0[i][j]:\n",
    "            weights += weight_cat_norm[j]\n",
    "    cat_weights_gstatus0.append(weights)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(recipient_class_gstatus1)):\n",
    "    weights = 0\n",
    "    for j in range(len(recipient_class_gstatus1[i])):\n",
    "        if recipient_class_gstatus1[i][j] == donor_class_gstatus1[i][j]:\n",
    "            weights += weight_cat_norm[j]\n",
    "    cat_weights_gstatus1.append(weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding for Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39162, 208)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENDER_F</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>ABO_A</th>\n",
       "      <th>ABO_A1</th>\n",
       "      <th>ABO_A1B</th>\n",
       "      <th>ABO_A2</th>\n",
       "      <th>ABO_A2B</th>\n",
       "      <th>ABO_AB</th>\n",
       "      <th>ABO_B</th>\n",
       "      <th>ABO_O</th>\n",
       "      <th>...</th>\n",
       "      <th>HISTORY_MI_DON_N</th>\n",
       "      <th>HISTORY_MI_DON_U</th>\n",
       "      <th>HISTORY_MI_DON_Y</th>\n",
       "      <th>CORONARY_ANGIO_DON_N</th>\n",
       "      <th>CORONARY_ANGIO_DON_Y</th>\n",
       "      <th>LIST_MELD_No</th>\n",
       "      <th>TX_MELD_No</th>\n",
       "      <th>LT_ONE_WEEK_DON_N</th>\n",
       "      <th>DATA_WAITLIST_Y</th>\n",
       "      <th>DATA_TRANSPLANT_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GENDER_F  GENDER_M  ABO_A  ABO_A1  ABO_A1B  ABO_A2  ABO_A2B  ABO_AB  ABO_B  \\\n",
       "0         0         1      1       0        0       0        0       0      0   \n",
       "1         0         1      0       0        0       0        0       0      0   \n",
       "2         1         0      0       0        0       0        0       0      1   \n",
       "3         0         1      0       0        0       0        0       0      1   \n",
       "4         0         1      0       0        0       0        0       0      0   \n",
       "\n",
       "   ABO_O        ...          HISTORY_MI_DON_N  HISTORY_MI_DON_U  \\\n",
       "0      0        ...                         1                 0   \n",
       "1      1        ...                         1                 0   \n",
       "2      0        ...                         1                 0   \n",
       "3      0        ...                         1                 0   \n",
       "4      1        ...                         1                 0   \n",
       "\n",
       "   HISTORY_MI_DON_Y  CORONARY_ANGIO_DON_N  CORONARY_ANGIO_DON_Y  LIST_MELD_No  \\\n",
       "0                 0                     1                     0             1   \n",
       "1                 0                     1                     0             1   \n",
       "2                 0                     1                     0             1   \n",
       "3                 0                     1                     0             1   \n",
       "4                 0                     1                     0             1   \n",
       "\n",
       "   TX_MELD_No  LT_ONE_WEEK_DON_N  DATA_WAITLIST_Y  DATA_TRANSPLANT_Y  \n",
       "0           1                  1                1                  1  \n",
       "1           1                  1                1                  1  \n",
       "2           1                  1                1                  1  \n",
       "3           1                  1                1                  1  \n",
       "4           1                  1                1                  1  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cfn=pd.get_dummies(X_cf)\n",
    "print(X_cfn.shape)\n",
    "X_cfn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Null Values for Non - Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non categorical features\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X_ncf)\n",
    "X_ncf = pd.DataFrame(imp.transform(X_ncf),columns = X_ncf.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23  1  6  8  0]\n",
      "[0, 3, 2, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "list1=[23,1,6,8,0]\n",
    "\n",
    "arr1=np.array(list1)\n",
    "print (arr1)\n",
    "print (list(arr1.argsort())[::-1][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "header=X_ncf.columns\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_ncf)\n",
    "X_ncf=pd.DataFrame(X_train_minmax,columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39162, 278)\n"
     ]
    }
   ],
   "source": [
    "#merge categorical and non-categorical features\n",
    "result = pd.merge(X_ncf, X_cfn,left_index=True,right_index=True)\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching for continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=5.4620759287569625, pvalue=4.7345693336526015e-08)\n",
      "Ttest_indResult(statistic=-6.118624127626865, pvalue=9.527954947230177e-10)\n",
      "Ttest_indResult(statistic=-1.922643877434707, pvalue=0.05453203429231182)\n",
      "Ttest_indResult(statistic=-4.823512603757652, pvalue=1.4158132010364828e-06)\n",
      "Ttest_indResult(statistic=2.410839649330238, pvalue=0.015920419504155896)\n"
     ]
    }
   ],
   "source": [
    "#Recepients\n",
    "liver_df_gstatus0 = result.loc[result['GSTATUS'] == 0]\n",
    "liver_df_gstatus1 = result.loc[result['GSTATUS'] == 1]\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['BMI_CALC'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['BMI_CALC'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['BMI_CALC'],liver_df2['BMI_CALC']))\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['CREAT_TX'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['CREAT_TX'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['CREAT_TX'],liver_df2['CREAT_TX']))\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['TBILI_TX'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['TBILI_TX'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['TBILI_TX'],liver_df2['TBILI_TX']))\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['HGT_CM_CALC'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['HGT_CM_CALC'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['HGT_CM_CALC'],liver_df2['HGT_CM_CALC']))\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['WGT_KG_CALC'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['WGT_KG_CALC'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['WGT_KG_CALC'],liver_df2['WGT_KG_CALC']))\n",
    "\n",
    "weight_cat = [16.9823,0.1322,5.9427,11.3336]\n",
    "weight_cat_norm = [1,0.0183,0.3499,0.6673]\n",
    "recipient_weights_cont = [0.8926*10,1*10,0.3142*10,0.7883,0.3940*10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=2.7330502594820385, pvalue=0.006277891372224274)\n",
      "Ttest_indResult(statistic=1.1295205067656648, pvalue=0.2586852425321753)\n",
      "Ttest_indResult(statistic=-1.670970443453076, pvalue=0.09473550667059624)\n",
      "Ttest_indResult(statistic=5.019333630605845, pvalue=5.20779640848788e-07)\n",
      "Ttest_indResult(statistic=4.869530386776263, pvalue=1.1229933706501736e-06)\n"
     ]
    }
   ],
   "source": [
    "#Donors\n",
    "\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['BMI_DON_CALC'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['BMI_DON_CALC'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['BMI_DON_CALC'],liver_df2['BMI_DON_CALC']))\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['CREAT_DON'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['CREAT_DON'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['CREAT_DON'],liver_df2['CREAT_DON']))\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['TBILI_DON'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['TBILI_DON'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['TBILI_DON'],liver_df2['TBILI_DON']))\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['HGT_CM_DON_CALC'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['HGT_CM_DON_CALC'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['HGT_CM_DON_CALC'],liver_df2['HGT_CM_DON_CALC']))\n",
    "\n",
    "liver_df1 = liver_df_gstatus0.dropna(subset=['WGT_KG_DON_CALC'])\n",
    "liver_df2 = liver_df_gstatus1.dropna(subset=['WGT_KG_DON_CALC'])\n",
    "print(scipy.stats.ttest_ind(liver_df1['WGT_KG_DON_CALC'],liver_df2['WGT_KG_DON_CALC']))\n",
    "\n",
    "\n",
    "donor_weights_cont = [0.4466*10,0.1846*10,0.2730*10,0.8203*10,0.7958*10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing score for continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27505, 1)\n"
     ]
    }
   ],
   "source": [
    "recepient_cont_gstatus0 = np.array(liver_df_gstatus0[['BMI_CALC','CREAT_TX','TBILI_TX','HGT_CM_CALC','WGT_KG_CALC']])\n",
    "recepient_cont_gstatus1 = np.array(liver_df_gstatus1[['BMI_CALC','CREAT_TX','TBILI_TX','HGT_CM_CALC','WGT_KG_CALC']])\n",
    "\n",
    "donor_cont_gstatus0 = np.array(liver_df_gstatus0[['BMI_DON_CALC','CREAT_DON','TBILI_DON','HGT_CM_DON_CALC','WGT_KG_DON_CALC']])\n",
    "donor_cont_gstatus1 = np.array(liver_df_gstatus1[['BMI_DON_CALC','CREAT_DON','TBILI_DON','HGT_CM_DON_CALC','WGT_KG_DON_CALC']])\n",
    "\n",
    "dist_gstatus_0 = np.sum(((recipient_weights_cont*recepient_cont_gstatus0)-(donor_weights_cont*donor_cont_gstatus0))**2,axis=-1, keepdims=True)**0.5\n",
    "dist_gstatus_1 = np.sum(((recipient_weights_cont*recepient_cont_gstatus1)-(donor_weights_cont*donor_cont_gstatus1))**2,axis=-1, keepdims=True)**0.5\n",
    "\n",
    "print(np.shape(dist_gstatus_0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing score for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical score\n",
    "cat_weights_gstatus_1 = np.array(cat_weights_gstatus1)\n",
    "cat_weights_gstatus_0 = np.array(cat_weights_gstatus0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Matching score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gstatus_0 = []\n",
    "final_gstatus_1 = []\n",
    "\n",
    "for i in range(len(dist_gstatus_0)):\n",
    "        final_gstatus_0.append(dist_gstatus_0[i]+cat_weights_gstatus_0[i])\n",
    "        \n",
    "for i in range(len(dist_gstatus_1)):\n",
    "        final_gstatus_1.append(dist_gstatus_1[i]+cat_weights_gstatus_1[i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the difference between the mean of two distributions (gstatus =0 and1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=array([4.61071389]), pvalue=array([4.02554922e-06]))\n"
     ]
    }
   ],
   "source": [
    "print(scipy.stats.ttest_ind(np.array(final_gstatus_0),np.array(final_gstatus_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X and Y to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39162, 237)\n",
      "(39162, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM_PREV_TX</th>\n",
       "      <th>DIAB</th>\n",
       "      <th>REM_CD</th>\n",
       "      <th>DAYSWAIT_CHRON</th>\n",
       "      <th>END_STAT</th>\n",
       "      <th>END_BMI_CALC</th>\n",
       "      <th>FINAL_ALBUMIN</th>\n",
       "      <th>FINAL_ASCITES</th>\n",
       "      <th>FINAL_BILIRUBIN</th>\n",
       "      <th>FINAL_ENCEPH</th>\n",
       "      <th>...</th>\n",
       "      <th>PROTEIN_URINE_Y</th>\n",
       "      <th>INOTROP_SUPPORT_DON_N</th>\n",
       "      <th>INOTROP_SUPPORT_DON_U</th>\n",
       "      <th>INOTROP_SUPPORT_DON_Y</th>\n",
       "      <th>CDC_RISK_HIV_DON_N</th>\n",
       "      <th>CDC_RISK_HIV_DON_Y</th>\n",
       "      <th>HISTORY_MI_DON_U</th>\n",
       "      <th>HISTORY_MI_DON_Y</th>\n",
       "      <th>CORONARY_ANGIO_DON_N</th>\n",
       "      <th>CORONARY_ANGIO_DON_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011615</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.280124</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.216380</td>\n",
       "      <td>0.415921</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.039175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.128445</td>\n",
       "      <td>0.215369</td>\n",
       "      <td>0.244989</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.170103</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.225480</td>\n",
       "      <td>0.332678</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.219414</td>\n",
       "      <td>0.095644</td>\n",
       "      <td>0.223404</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.153418</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.230536</td>\n",
       "      <td>0.208254</td>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.227503</td>\n",
       "      <td>0.322488</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.050515</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.216380</td>\n",
       "      <td>0.395840</td>\n",
       "      <td>0.223404</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.094021</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.046686</td>\n",
       "      <td>0.222447</td>\n",
       "      <td>0.200581</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.037577</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.221391</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.022680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.214358</td>\n",
       "      <td>0.247234</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.172165</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>0.260646</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.115464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.226491</td>\n",
       "      <td>0.247593</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.029897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.214358</td>\n",
       "      <td>0.210155</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.029834</td>\n",
       "      <td>0.216380</td>\n",
       "      <td>0.269894</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.219414</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.015464</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.283009</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.213347</td>\n",
       "      <td>0.237340</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.027835</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.220425</td>\n",
       "      <td>0.311118</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057732</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.229525</td>\n",
       "      <td>0.216789</td>\n",
       "      <td>0.223404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.010020</td>\n",
       "      <td>0.210313</td>\n",
       "      <td>0.292151</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.216380</td>\n",
       "      <td>0.313369</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.167010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.208291</td>\n",
       "      <td>0.355257</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172165</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.478251</td>\n",
       "      <td>0.215369</td>\n",
       "      <td>0.327868</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.226491</td>\n",
       "      <td>0.220024</td>\n",
       "      <td>0.138298</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.013402</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.168299</td>\n",
       "      <td>0.226491</td>\n",
       "      <td>0.120549</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013402</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.049192</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.372360</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.015942</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.249621</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111340</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.041676</td>\n",
       "      <td>0.214358</td>\n",
       "      <td>0.234204</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073196</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39132</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.226491</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.581443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39133</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.208291</td>\n",
       "      <td>0.282720</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.084536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39134</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.386338</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39135</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.228514</td>\n",
       "      <td>0.422470</td>\n",
       "      <td>0.308511</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.323711</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39136</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.221436</td>\n",
       "      <td>0.361103</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39137</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.260146</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.096907</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39138</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.223458</td>\n",
       "      <td>0.374754</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015464</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39139</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.216380</td>\n",
       "      <td>0.369438</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39140</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.202224</td>\n",
       "      <td>0.212894</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39141</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262938</td>\n",
       "      <td>0.223404</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049485</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39142</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.274416</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.025773</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39143</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.224469</td>\n",
       "      <td>0.186676</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.171134</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39144</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.216380</td>\n",
       "      <td>0.408264</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.024742</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39145</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.266960</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.019588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39146</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.195147</td>\n",
       "      <td>0.255583</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39147</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.226491</td>\n",
       "      <td>0.395271</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013402</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39148</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.212336</td>\n",
       "      <td>0.479925</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.055670</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39149</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.214358</td>\n",
       "      <td>0.375262</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.434021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39150</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.214358</td>\n",
       "      <td>0.232814</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39151</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.208291</td>\n",
       "      <td>0.207186</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.292784</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39152</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.215369</td>\n",
       "      <td>0.296306</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39153</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.449444</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.049485</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39154</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.218402</td>\n",
       "      <td>0.393963</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39155</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.204247</td>\n",
       "      <td>0.249332</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39156</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.225480</td>\n",
       "      <td>0.267397</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.052577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39157</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.328415</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.060825</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39158</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.553402</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.022680</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39159</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.215369</td>\n",
       "      <td>0.314092</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39160</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.227503</td>\n",
       "      <td>0.406772</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.315464</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39161</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.219414</td>\n",
       "      <td>0.423749</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39162 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NUM_PREV_TX      DIAB    REM_CD  DAYSWAIT_CHRON  END_STAT  \\\n",
       "0         0.000000  0.002006  1.000000        0.011615  0.217391   \n",
       "1         0.000000  0.000000  0.666667        0.002050  0.216380   \n",
       "2         0.000000  0.000000  0.055556        0.128445  0.215369   \n",
       "3         0.000000  0.000000  0.055556        0.002733  0.225480   \n",
       "4         0.000000  0.000000  0.055556        0.008199  0.219414   \n",
       "5         0.000000  0.000000  0.055556        0.001366  0.002022   \n",
       "6         0.000000  0.000000  0.055556        0.002505  0.230536   \n",
       "7         0.000000  0.002006  0.055556        0.003872  0.227503   \n",
       "8         0.111111  0.000000  0.055556        0.003872  0.216380   \n",
       "9         0.000000  0.002006  0.055556        0.046686  0.222447   \n",
       "10        0.000000  0.000000  0.055556        0.037577  0.232558   \n",
       "11        0.000000  0.000000  0.055556        0.000228  0.214358   \n",
       "12        0.000000  0.000000  0.055556        0.004783  0.192113   \n",
       "13        0.000000  0.000000  0.055556        0.004783  0.226491   \n",
       "14        0.000000  0.002006  0.055556        0.000683  0.214358   \n",
       "15        0.000000  0.000000  0.055556        0.029834  0.216380   \n",
       "16        0.000000  0.000000  0.055556        0.008654  0.219414   \n",
       "17        0.000000  0.002006  0.666667        0.001139  0.001011   \n",
       "18        0.000000  0.000000  0.055556        0.000683  0.213347   \n",
       "19        0.111111  0.002006  0.055556        0.001594  0.220425   \n",
       "20        0.000000  0.002006  0.055556        0.002277  0.229525   \n",
       "21        0.000000  0.002006  0.055556        0.010020  0.210313   \n",
       "22        0.000000  0.001003  0.055556        0.000911  0.216380   \n",
       "23        0.000000  0.000000  0.055556        0.000228  0.208291   \n",
       "24        0.000000  0.000000  0.055556        0.478251  0.215369   \n",
       "25        0.000000  0.000000  0.055556        0.001594  0.226491   \n",
       "26        0.000000  0.000000  0.055556        0.168299  0.226491   \n",
       "27        0.000000  0.000000  0.055556        0.049192  0.232558   \n",
       "28        0.000000  0.000000  0.055556        0.015942  0.001011   \n",
       "29        0.111111  0.000000  0.055556        0.041676  0.214358   \n",
       "...            ...       ...       ...             ...       ...   \n",
       "39132     0.000000  0.000000  0.055556        0.001139  0.226491   \n",
       "39133     0.000000  0.002006  0.055556        0.002733  0.208291   \n",
       "39134     0.000000  0.001003  0.055556        0.001139  0.232558   \n",
       "39135     0.000000  0.000000  0.055556        0.000683  0.228514   \n",
       "39136     0.000000  0.000000  0.055556        0.001139  0.221436   \n",
       "39137     0.000000  0.002006  0.666667        0.000228  0.232558   \n",
       "39138     0.000000  0.000000  0.055556        0.000683  0.223458   \n",
       "39139     0.000000  0.001003  0.055556        0.002961  0.216380   \n",
       "39140     0.000000  0.002006  0.055556        0.001366  0.202224   \n",
       "39141     0.000000  0.002006  0.055556        0.000228  0.000000   \n",
       "39142     0.000000  0.002006  0.055556        0.001366  0.001011   \n",
       "39143     0.000000  0.002006  0.055556        0.001822  0.224469   \n",
       "39144     0.000000  0.000000  0.055556        0.000455  0.216380   \n",
       "39145     0.000000  0.000000  0.055556        0.001366  0.232558   \n",
       "39146     0.000000  0.002006  0.055556        0.001366  0.195147   \n",
       "39147     0.000000  0.000000  0.055556        0.001594  0.226491   \n",
       "39148     0.000000  0.000000  0.055556        0.000455  0.212336   \n",
       "39149     0.000000  0.000000  0.055556        0.001139  0.214358   \n",
       "39150     0.000000  0.000000  0.666667        0.001822  0.214358   \n",
       "39151     0.000000  0.000000  0.055556        0.000228  0.208291   \n",
       "39152     0.000000  0.002006  0.055556        0.001594  0.215369   \n",
       "39153     0.000000  0.000000  0.055556        0.000683  0.217391   \n",
       "39154     0.000000  0.000000  0.055556        0.000455  0.218402   \n",
       "39155     0.000000  0.000000  0.055556        0.000683  0.204247   \n",
       "39156     0.111111  0.000000  0.055556        0.000683  0.225480   \n",
       "39157     0.000000  0.000000  0.055556        0.000228  0.232558   \n",
       "39158     0.000000  0.000000  0.055556        0.000455  0.217391   \n",
       "39159     0.111111  0.001003  0.055556        0.000683  0.215369   \n",
       "39160     0.000000  0.000000  0.055556        0.000683  0.227503   \n",
       "39161     0.000000  0.000000  0.055556        0.000228  0.219414   \n",
       "\n",
       "       END_BMI_CALC  FINAL_ALBUMIN  FINAL_ASCITES  FINAL_BILIRUBIN  \\\n",
       "0          0.280124       0.287234       0.666667         0.041237   \n",
       "1          0.415921       0.180851       0.333333         0.039175   \n",
       "2          0.244989       0.372340       0.333333         0.170103   \n",
       "3          0.332678       0.191489       0.666667         0.041237   \n",
       "4          0.095644       0.223404       0.333333         0.054639   \n",
       "5          0.153418       0.393617       0.666667         0.005155   \n",
       "6          0.208254       0.351064       0.333333         0.011340   \n",
       "7          0.322488       0.255319       0.333333         0.050515   \n",
       "8          0.395840       0.223404       0.666667         0.094021   \n",
       "9          0.200581       0.202128       0.333333         0.030928   \n",
       "10         0.221391       0.287234       0.333333         0.022680   \n",
       "11         0.247234       0.329787       0.666667         0.172165   \n",
       "12         0.260646       0.265957       0.666667         0.115464   \n",
       "13         0.247593       0.276596       0.666667         0.029897   \n",
       "14         0.210155       0.372340       0.666667         0.041237   \n",
       "15         0.269894       0.265957       0.666667         0.036082   \n",
       "16         0.232918       0.297872       0.333333         0.015464   \n",
       "17         0.283009       0.329787       0.333333         0.003093   \n",
       "18         0.237340       0.127660       0.333333         0.027835   \n",
       "19         0.311118       0.340426       0.000000         0.057732   \n",
       "20         0.216789       0.223404       0.000000         0.036082   \n",
       "21         0.292151       0.404255       0.333333         0.025773   \n",
       "22         0.313369       0.500000       0.666667         0.167010   \n",
       "23         0.355257       0.329787       0.000000         0.172165   \n",
       "24         0.327868       0.244681       0.000000         0.526804   \n",
       "25         0.220024       0.138298       0.666667         0.013402   \n",
       "26         0.120549       0.244681       0.000000         0.013402   \n",
       "27         0.372360       0.329787       0.000000         0.129897   \n",
       "28         0.249621       0.297872       0.666667         0.111340   \n",
       "29         0.234204       0.265957       0.000000         0.073196   \n",
       "...             ...            ...            ...              ...   \n",
       "39132      0.356691       0.255319       0.333333         0.581443   \n",
       "39133      0.282720       0.297872       0.333333         0.084536   \n",
       "39134      0.386338       0.297872       0.333333         0.008247   \n",
       "39135      0.422470       0.308511       0.333333         0.323711   \n",
       "39136      0.361103       0.361702       0.000000         0.270103   \n",
       "39137      0.260146       0.319149       0.333333         0.096907   \n",
       "39138      0.374754       0.382979       0.000000         0.015464   \n",
       "39139      0.369438       0.340426       0.000000         0.024742   \n",
       "39140      0.212894       0.202128       0.333333         0.072165   \n",
       "39141      0.262938       0.223404       0.333333         0.049485   \n",
       "39142      0.274416       0.212766       0.666667         0.025773   \n",
       "39143      0.186676       0.404255       0.333333         0.171134   \n",
       "39144      0.408264       0.234043       0.333333         0.024742   \n",
       "39145      0.266960       0.361702       0.333333         0.019588   \n",
       "39146      0.255583       0.212766       0.333333         0.054639   \n",
       "39147      0.395271       0.319149       0.000000         0.013402   \n",
       "39148      0.479925       0.340426       0.333333         0.055670   \n",
       "39149      0.375262       0.244681       0.333333         0.434021   \n",
       "39150      0.232814       0.265957       0.666667         0.042268   \n",
       "39151      0.207186       0.244681       0.666667         0.292784   \n",
       "39152      0.296306       0.191489       0.000000         0.286598   \n",
       "39153      0.449444       0.329787       0.666667         0.049485   \n",
       "39154      0.393963       0.212766       0.333333         0.012371   \n",
       "39155      0.249332       0.234043       0.666667         0.082474   \n",
       "39156      0.267397       0.255319       0.666667         0.052577   \n",
       "39157      0.328415       0.265957       0.333333         0.060825   \n",
       "39158      0.553402       0.265957       0.333333         0.022680   \n",
       "39159      0.314092       0.276596       0.666667         0.011340   \n",
       "39160      0.406772       0.393617       0.666667         0.315464   \n",
       "39161      0.423749       0.382979       0.666667         0.020619   \n",
       "\n",
       "       FINAL_ENCEPH          ...           PROTEIN_URINE_Y  \\\n",
       "0          0.000000          ...                         0   \n",
       "1          0.000000          ...                         1   \n",
       "2          0.333333          ...                         0   \n",
       "3          0.333333          ...                         1   \n",
       "4          0.666667          ...                         0   \n",
       "5          0.000000          ...                         1   \n",
       "6          0.000000          ...                         0   \n",
       "7          0.333333          ...                         0   \n",
       "8          0.333333          ...                         0   \n",
       "9          0.000000          ...                         0   \n",
       "10         0.000000          ...                         1   \n",
       "11         0.333333          ...                         0   \n",
       "12         0.000000          ...                         1   \n",
       "13         0.000000          ...                         0   \n",
       "14         0.333333          ...                         0   \n",
       "15         0.000000          ...                         1   \n",
       "16         0.666667          ...                         0   \n",
       "17         0.000000          ...                         0   \n",
       "18         0.333333          ...                         1   \n",
       "19         0.333333          ...                         0   \n",
       "20         0.333333          ...                         1   \n",
       "21         0.000000          ...                         1   \n",
       "22         0.000000          ...                         0   \n",
       "23         0.333333          ...                         0   \n",
       "24         0.000000          ...                         1   \n",
       "25         0.666667          ...                         0   \n",
       "26         0.333333          ...                         0   \n",
       "27         1.000000          ...                         0   \n",
       "28         0.333333          ...                         0   \n",
       "29         0.333333          ...                         0   \n",
       "...             ...          ...                       ...   \n",
       "39132      0.000000          ...                         1   \n",
       "39133      0.000000          ...                         1   \n",
       "39134      0.333333          ...                         0   \n",
       "39135      0.333333          ...                         0   \n",
       "39136      0.000000          ...                         0   \n",
       "39137      0.333333          ...                         1   \n",
       "39138      0.333333          ...                         0   \n",
       "39139      0.000000          ...                         0   \n",
       "39140      0.333333          ...                         1   \n",
       "39141      0.333333          ...                         0   \n",
       "39142      0.333333          ...                         1   \n",
       "39143      0.333333          ...                         1   \n",
       "39144      0.333333          ...                         1   \n",
       "39145      1.000000          ...                         0   \n",
       "39146      0.333333          ...                         0   \n",
       "39147      0.666667          ...                         0   \n",
       "39148      0.333333          ...                         0   \n",
       "39149      0.000000          ...                         0   \n",
       "39150      0.000000          ...                         0   \n",
       "39151      0.333333          ...                         0   \n",
       "39152      0.000000          ...                         0   \n",
       "39153      0.666667          ...                         0   \n",
       "39154      0.666667          ...                         0   \n",
       "39155      0.333333          ...                         1   \n",
       "39156      0.000000          ...                         0   \n",
       "39157      0.333333          ...                         1   \n",
       "39158      0.333333          ...                         0   \n",
       "39159      0.333333          ...                         0   \n",
       "39160      0.333333          ...                         0   \n",
       "39161      0.000000          ...                         1   \n",
       "\n",
       "       INOTROP_SUPPORT_DON_N  INOTROP_SUPPORT_DON_U  INOTROP_SUPPORT_DON_Y  \\\n",
       "0                          1                      0                      0   \n",
       "1                          0                      0                      1   \n",
       "2                          1                      0                      0   \n",
       "3                          1                      0                      0   \n",
       "4                          1                      0                      0   \n",
       "5                          0                      0                      1   \n",
       "6                          1                      0                      0   \n",
       "7                          1                      0                      0   \n",
       "8                          1                      0                      0   \n",
       "9                          1                      0                      0   \n",
       "10                         0                      0                      1   \n",
       "11                         0                      0                      1   \n",
       "12                         1                      0                      0   \n",
       "13                         0                      0                      1   \n",
       "14                         1                      0                      0   \n",
       "15                         0                      0                      1   \n",
       "16                         0                      0                      1   \n",
       "17                         0                      0                      1   \n",
       "18                         1                      0                      0   \n",
       "19                         1                      0                      0   \n",
       "20                         1                      0                      0   \n",
       "21                         0                      0                      1   \n",
       "22                         1                      0                      0   \n",
       "23                         1                      0                      0   \n",
       "24                         1                      0                      0   \n",
       "25                         1                      0                      0   \n",
       "26                         0                      0                      1   \n",
       "27                         1                      0                      0   \n",
       "28                         1                      0                      0   \n",
       "29                         0                      0                      1   \n",
       "...                      ...                    ...                    ...   \n",
       "39132                      1                      0                      0   \n",
       "39133                      1                      0                      0   \n",
       "39134                      0                      0                      1   \n",
       "39135                      1                      0                      0   \n",
       "39136                      0                      0                      1   \n",
       "39137                      0                      0                      1   \n",
       "39138                      0                      0                      1   \n",
       "39139                      1                      0                      0   \n",
       "39140                      0                      0                      1   \n",
       "39141                      0                      0                      1   \n",
       "39142                      1                      0                      0   \n",
       "39143                      0                      0                      1   \n",
       "39144                      0                      0                      1   \n",
       "39145                      1                      0                      0   \n",
       "39146                      0                      0                      1   \n",
       "39147                      1                      0                      0   \n",
       "39148                      0                      0                      1   \n",
       "39149                      1                      0                      0   \n",
       "39150                      0                      0                      1   \n",
       "39151                      1                      0                      0   \n",
       "39152                      1                      0                      0   \n",
       "39153                      0                      0                      1   \n",
       "39154                      0                      0                      1   \n",
       "39155                      1                      0                      0   \n",
       "39156                      0                      0                      1   \n",
       "39157                      1                      0                      0   \n",
       "39158                      1                      0                      0   \n",
       "39159                      0                      0                      1   \n",
       "39160                      0                      0                      1   \n",
       "39161                      1                      0                      0   \n",
       "\n",
       "       CDC_RISK_HIV_DON_N  CDC_RISK_HIV_DON_Y  HISTORY_MI_DON_U  \\\n",
       "0                       1                   0                 0   \n",
       "1                       1                   0                 0   \n",
       "2                       1                   0                 0   \n",
       "3                       1                   0                 0   \n",
       "4                       1                   0                 0   \n",
       "5                       1                   0                 0   \n",
       "6                       1                   0                 0   \n",
       "7                       1                   0                 0   \n",
       "8                       1                   0                 0   \n",
       "9                       1                   0                 0   \n",
       "10                      1                   0                 0   \n",
       "11                      1                   0                 0   \n",
       "12                      1                   0                 0   \n",
       "13                      1                   0                 0   \n",
       "14                      1                   0                 0   \n",
       "15                      1                   0                 0   \n",
       "16                      1                   0                 0   \n",
       "17                      0                   1                 0   \n",
       "18                      1                   0                 0   \n",
       "19                      1                   0                 0   \n",
       "20                      1                   0                 0   \n",
       "21                      1                   0                 0   \n",
       "22                      1                   0                 0   \n",
       "23                      1                   0                 0   \n",
       "24                      1                   0                 0   \n",
       "25                      1                   0                 0   \n",
       "26                      1                   0                 0   \n",
       "27                      1                   0                 0   \n",
       "28                      1                   0                 0   \n",
       "29                      1                   0                 0   \n",
       "...                   ...                 ...               ...   \n",
       "39132                   1                   0                 0   \n",
       "39133                   1                   0                 0   \n",
       "39134                   1                   0                 0   \n",
       "39135                   1                   0                 0   \n",
       "39136                   1                   0                 0   \n",
       "39137                   1                   0                 0   \n",
       "39138                   1                   0                 0   \n",
       "39139                   1                   0                 0   \n",
       "39140                   1                   0                 1   \n",
       "39141                   1                   0                 0   \n",
       "39142                   1                   0                 0   \n",
       "39143                   1                   0                 0   \n",
       "39144                   1                   0                 0   \n",
       "39145                   1                   0                 0   \n",
       "39146                   0                   1                 0   \n",
       "39147                   1                   0                 0   \n",
       "39148                   1                   0                 0   \n",
       "39149                   1                   0                 0   \n",
       "39150                   1                   0                 0   \n",
       "39151                   1                   0                 0   \n",
       "39152                   1                   0                 0   \n",
       "39153                   1                   0                 0   \n",
       "39154                   1                   0                 0   \n",
       "39155                   0                   1                 0   \n",
       "39156                   0                   1                 0   \n",
       "39157                   1                   0                 0   \n",
       "39158                   1                   0                 0   \n",
       "39159                   1                   0                 0   \n",
       "39160                   1                   0                 0   \n",
       "39161                   1                   0                 0   \n",
       "\n",
       "       HISTORY_MI_DON_Y  CORONARY_ANGIO_DON_N  CORONARY_ANGIO_DON_Y  \n",
       "0                     0                     1                     0  \n",
       "1                     0                     1                     0  \n",
       "2                     0                     1                     0  \n",
       "3                     0                     1                     0  \n",
       "4                     0                     1                     0  \n",
       "5                     0                     0                     1  \n",
       "6                     0                     1                     0  \n",
       "7                     0                     1                     0  \n",
       "8                     0                     1                     0  \n",
       "9                     0                     1                     0  \n",
       "10                    0                     1                     0  \n",
       "11                    0                     1                     0  \n",
       "12                    0                     0                     1  \n",
       "13                    0                     1                     0  \n",
       "14                    0                     1                     0  \n",
       "15                    0                     1                     0  \n",
       "16                    0                     0                     1  \n",
       "17                    0                     0                     1  \n",
       "18                    0                     0                     1  \n",
       "19                    0                     1                     0  \n",
       "20                    0                     0                     1  \n",
       "21                    0                     1                     0  \n",
       "22                    0                     1                     0  \n",
       "23                    1                     1                     0  \n",
       "24                    0                     0                     1  \n",
       "25                    0                     1                     0  \n",
       "26                    0                     0                     1  \n",
       "27                    0                     0                     1  \n",
       "28                    0                     1                     0  \n",
       "29                    0                     0                     1  \n",
       "...                 ...                   ...                   ...  \n",
       "39132                 0                     1                     0  \n",
       "39133                 0                     1                     0  \n",
       "39134                 0                     1                     0  \n",
       "39135                 1                     1                     0  \n",
       "39136                 0                     1                     0  \n",
       "39137                 0                     1                     0  \n",
       "39138                 0                     1                     0  \n",
       "39139                 0                     1                     0  \n",
       "39140                 0                     1                     0  \n",
       "39141                 0                     1                     0  \n",
       "39142                 0                     1                     0  \n",
       "39143                 0                     1                     0  \n",
       "39144                 0                     1                     0  \n",
       "39145                 0                     1                     0  \n",
       "39146                 1                     1                     0  \n",
       "39147                 0                     1                     0  \n",
       "39148                 0                     1                     0  \n",
       "39149                 0                     1                     0  \n",
       "39150                 0                     1                     0  \n",
       "39151                 0                     1                     0  \n",
       "39152                 0                     1                     0  \n",
       "39153                 0                     0                     1  \n",
       "39154                 0                     0                     1  \n",
       "39155                 0                     1                     0  \n",
       "39156                 0                     1                     0  \n",
       "39157                 0                     1                     0  \n",
       "39158                 0                     1                     0  \n",
       "39159                 0                     1                     0  \n",
       "39160                 0                     1                     0  \n",
       "39161                 0                     1                     0  \n",
       "\n",
       "[39162 rows x 237 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSTATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39132</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39133</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39134</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39135</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39136</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39137</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39138</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39139</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39140</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39141</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39142</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39143</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39144</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39145</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39146</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39147</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39148</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39149</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39150</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39151</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39152</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39153</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39154</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39155</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39156</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39157</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39158</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39159</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39160</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39161</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39162 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GSTATUS\n",
       "0          1.0\n",
       "1          1.0\n",
       "2          1.0\n",
       "3          0.0\n",
       "4          1.0\n",
       "5          1.0\n",
       "6          0.0\n",
       "7          0.0\n",
       "8          0.0\n",
       "9          0.0\n",
       "10         1.0\n",
       "11         0.0\n",
       "12         0.0\n",
       "13         0.0\n",
       "14         0.0\n",
       "15         1.0\n",
       "16         0.0\n",
       "17         0.0\n",
       "18         0.0\n",
       "19         0.0\n",
       "20         1.0\n",
       "21         0.0\n",
       "22         0.0\n",
       "23         1.0\n",
       "24         0.0\n",
       "25         1.0\n",
       "26         0.0\n",
       "27         1.0\n",
       "28         0.0\n",
       "29         0.0\n",
       "...        ...\n",
       "39132      1.0\n",
       "39133      0.0\n",
       "39134      0.0\n",
       "39135      1.0\n",
       "39136      0.0\n",
       "39137      0.0\n",
       "39138      0.0\n",
       "39139      0.0\n",
       "39140      0.0\n",
       "39141      0.0\n",
       "39142      0.0\n",
       "39143      0.0\n",
       "39144      0.0\n",
       "39145      0.0\n",
       "39146      0.0\n",
       "39147      0.0\n",
       "39148      0.0\n",
       "39149      0.0\n",
       "39150      0.0\n",
       "39151      0.0\n",
       "39152      0.0\n",
       "39153      0.0\n",
       "39154      0.0\n",
       "39155      0.0\n",
       "39156      0.0\n",
       "39157      0.0\n",
       "39158      0.0\n",
       "39159      0.0\n",
       "39160      0.0\n",
       "39161      0.0\n",
       "\n",
       "[39162 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "less_important_features=['ABO_DON_A2B','ABO_DON_AB','ANTIHYPE_DON_Y','CARDARREST_NEURO_N','CARDARREST_NEURO_Y','CDC_RISK_HIV_DON_U','CLIN_INFECT_DON_U','DATA_TRANSPLANT_Y','DATA_WAITLIST_Y','DIABETES_DON_U','DIAL_TX_N','DIAL_TX_Y','EXTRACRANIAL_CANCER_DON_Y','HBV_CORE_DON.1_U','HBV_CORE_DON_I','HBV_CORE_ND','HBV_CORE_U','HBV_SUR_ANTIGEN_DON_C','HBV_SUR_ANTIGEN_DON_I','HCV_SEROSTATUS_ND','HEP_C_ANTI_DON_C','HEP_C_ANTI_DON_I','HISTORY_MI_DON_N','HIST_CANCER_DON_U','HIST_OTH_DRUG_DON_U','HIV_SEROSTATUS_ND','HIV_SEROSTATUS_P','INSULIN_DON_Y','LIFE_SUP_TRR_N','LIFE_SUP_TRR_Y','LIST_MELD_No','LT_ONE_WEEK_DON_N','MALIG_TRR_Y','PT_T3_DON_N','PT_T3_DON_Y','SKIN_CANCER_DON_N','TXLIV_S','TXLIV_W','TX_MELD_No','VDRL_DON_I']\n",
    "cols = [col for col in result.columns if col not in less_important_features]\n",
    "X= result[cols]\n",
    "X = X[[column for column in X.columns if column != 'GSTATUS']]\n",
    "\n",
    "Y= result[['GSTATUS']]\n",
    "#print (list(X.columns))\n",
    "headers= ['NUM_PREV_TX', 'DIAB', 'REM_CD', 'DAYSWAIT_CHRON', 'END_STAT', 'END_BMI_CALC', 'FINAL_ALBUMIN', 'FINAL_ASCITES', 'FINAL_BILIRUBIN', 'FINAL_ENCEPH', 'FINAL_INR', 'FINAL_MELD_PELD_LAB_SCORE', 'FINAL_SERUM_CREAT', 'FINAL_SERUM_SODIUM', 'TX_PROCEDUR_TY', 'FUNC_STAT_TRR', 'MED_COND_TRR', 'PRI_PAYMENT_TRR', 'ON_VENT_TRR', 'ARTIFICIAL_LI_TRR', 'OTH_LIFE_SUP_TRR', 'DA1', 'DA2', 'DB1', 'DB2', 'DDR1', 'DDR2', 'AGE_DON', 'COD_CAD_DON', 'DEATH_CIRCUM_DON', 'DEATH_MECH_DON', 'BLOOD_INF_DON', 'BUN_DON', 'CREAT_DON', 'PULM_INF_DON', 'SGOT_DON', 'SGPT_DON', 'TBILI_DON', 'URINE_INF_DON', 'CANCER_SITE_DON', 'HIST_DIABETES_DON', 'HGT_CM_DON_CALC', 'WGT_KG_DON_CALC', 'BMI_DON_CALC', 'ECD_DONOR', 'CREAT_TX', 'TBILI_TX', 'INR_TX', 'ALBUMIN_TX', 'ENCEPH_TX', 'ASCITES_TX', 'MELD_PELD_LAB_SCORE', 'EXC_EVER', 'LITYP', 'LOS', 'AGE', 'DIAG', 'ABO_MAT', 'COLD_ISCH', 'SHARE_TY', 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC', 'DONOR_ID', 'TRANSFUS_TERM_DON', 'PH_DON', 'HEMATOCRIT_DON', 'TX_YEAR', 'LISTYR', 'GENDER_F', 'GENDER_M', 'ABO_A', 'ABO_A1', 'ABO_A1B', 'ABO_A2', 'ABO_A2B', 'ABO_AB', 'ABO_B', 'ABO_O', 'EXC_HCC_HBL', 'EXC_HCC_HCC', 'EXC_HCC_non-HCC', 'EXC_CASE_No', 'EXC_CASE_Yes', 'FINAL_DIALYSIS_PRIOR_WEEK_A', 'FINAL_DIALYSIS_PRIOR_WEEK_N', 'FINAL_DIALYSIS_PRIOR_WEEK_Y', 'FINAL_MELD_OR_PELD_MELD', 'FINAL_MELD_OR_PELD_PELD', 'MALIG_TRR_N', 'MALIG_TRR_U', 'PORTAL_VEIN_TRR_N', 'PORTAL_VEIN_TRR_U', 'PORTAL_VEIN_TRR_Y', 'PREV_AB_SURG_TRR_N', 'PREV_AB_SURG_TRR_U', 'PREV_AB_SURG_TRR_Y', 'TIPSS_TRR_N', 'TIPSS_TRR_U', 'TIPSS_TRR_Y', 'HBV_CORE_N', 'HBV_CORE_P', 'HBV_SUR_ANTIGEN_N', 'HBV_SUR_ANTIGEN_ND', 'HBV_SUR_ANTIGEN_P', 'HBV_SUR_ANTIGEN_U', 'HCV_SEROSTATUS_N', 'HCV_SEROSTATUS_P', 'HCV_SEROSTATUS_U', 'EBV_SEROSTATUS_N', 'EBV_SEROSTATUS_ND', 'EBV_SEROSTATUS_P', 'EBV_SEROSTATUS_U', 'HIV_SEROSTATUS_N', 'HIV_SEROSTATUS_U', 'CMV_STATUS_N', 'CMV_STATUS_ND', 'CMV_STATUS_P', 'CMV_STATUS_U', 'CMV_IGG_N', 'CMV_IGG_ND', 'CMV_IGG_P', 'CMV_IGG_U', 'CMV_IGM_N', 'CMV_IGM_ND', 'CMV_IGM_P', 'CMV_IGM_U', 'PREV_TX_N', 'PREV_TX_Y', 'DDAVP_DON_N', 'DDAVP_DON_U', 'DDAVP_DON_Y', 'CMV_DON_I', 'CMV_DON_N', 'CMV_DON_ND', 'CMV_DON_P', 'CMV_DON_U', 'HEP_C_ANTI_DON_N', 'HEP_C_ANTI_DON_ND', 'HEP_C_ANTI_DON_P', 'HEP_C_ANTI_DON_U', 'HBV_CORE_DON_N', 'HBV_CORE_DON_ND', 'HBV_CORE_DON_P', 'HBV_CORE_DON_U', 'HBV_SUR_ANTIGEN_DON_N', 'HBV_SUR_ANTIGEN_DON_ND', 'HBV_SUR_ANTIGEN_DON_P', 'HBV_SUR_ANTIGEN_DON_U', 'DON_TY_C', 'DON_TY_L', 'GENDER_DON_F', 'GENDER_DON_M', 'NON_HRT_DON_N', 'NON_HRT_DON_Y', 'ANTIHYPE_DON_N', 'ANTIHYPE_DON_U', 'PT_DIURETICS_DON_N', 'PT_DIURETICS_DON_U', 'PT_DIURETICS_DON_Y', 'PT_STEROIDS_DON_N', 'PT_STEROIDS_DON_U', 'PT_STEROIDS_DON_Y', 'PT_T3_DON_U', 'PT_T4_DON_N', 'PT_T4_DON_U', 'PT_T4_DON_Y', 'VASODIL_DON_N', 'VASODIL_DON_U', 'VASODIL_DON_Y', 'VDRL_DON_N', 'VDRL_DON_ND', 'VDRL_DON_P', 'VDRL_DON_U', 'CLIN_INFECT_DON_N', 'CLIN_INFECT_DON_Y', 'EXTRACRANIAL_CANCER_DON_N', 'EXTRACRANIAL_CANCER_DON_U', 'HIST_CIG_DON_N', 'HIST_CIG_DON_U', 'HIST_CIG_DON_Y', 'HIST_COCAINE_DON_N', 'HIST_COCAINE_DON_U', 'HIST_COCAINE_DON_Y', 'DIABETES_DON_N', 'DIABETES_DON_Y', 'HIST_HYPERTENS_DON_N', 'HIST_HYPERTENS_DON_U', 'HIST_HYPERTENS_DON_Y', 'HIST_OTH_DRUG_DON_N', 'HIST_OTH_DRUG_DON_Y', 'ABO_DON_A', 'ABO_DON_A1', 'ABO_DON_A1B', 'ABO_DON_A2', 'ABO_DON_B', 'ABO_DON_O', 'INTRACRANIAL_CANCER_DON_N', 'INTRACRANIAL_CANCER_DON_U', 'INTRACRANIAL_CANCER_DON_Y', 'SKIN_CANCER_DON_U', 'SKIN_CANCER_DON_Y', 'HIST_CANCER_DON_N', 'HIST_CANCER_DON_Y', 'PT_OTH_DON_N', 'PT_OTH_DON_Y', 'HEPARIN_DON_N', 'HEPARIN_DON_U', 'HEPARIN_DON_Y', 'HBV_CORE_DON.1_N', 'HBV_CORE_DON.1_Y', 'INSULIN_DON_N', 'INSULIN_DON_U', 'AGE_GROUP_A', 'AGE_GROUP_P', 'MALIG_N', 'MALIG_U', 'MALIG_Y', 'RECOV_OUT_US_N', 'RECOV_OUT_US_Y', 'TATTOOS_N', 'TATTOOS_U', 'TATTOOS_Y', 'LI_BIOPSY_N', 'LI_BIOPSY_Y', 'PROTEIN_URINE_N', 'PROTEIN_URINE_U', 'PROTEIN_URINE_Y', 'INOTROP_SUPPORT_DON_N', 'INOTROP_SUPPORT_DON_U', 'INOTROP_SUPPORT_DON_Y', 'CDC_RISK_HIV_DON_N', 'CDC_RISK_HIV_DON_Y', 'HISTORY_MI_DON_U', 'HISTORY_MI_DON_Y', 'CORONARY_ANGIO_DON_N', 'CORONARY_ANGIO_DON_Y']\n",
    "\n",
    "x_train=X\n",
    "y_train=Y\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "display(x_train)\n",
    "display(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.30, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_columns =['NUM_PREV_TX', 'DIAB', 'REM_CD', 'DAYSWAIT_CHRON', 'END_STAT', 'END_BMI_CALC', 'FINAL_ALBUMIN', 'FINAL_ASCITES', 'FINAL_BILIRUBIN', 'FINAL_ENCEPH', 'FINAL_INR', 'FINAL_MELD_PELD_LAB_SCORE', 'FINAL_SERUM_CREAT', 'FINAL_SERUM_SODIUM', 'TX_PROCEDUR_TY', 'FUNC_STAT_TRR', 'MED_COND_TRR', 'PRI_PAYMENT_TRR', 'ON_VENT_TRR', 'ARTIFICIAL_LI_TRR', 'OTH_LIFE_SUP_TRR', 'DA1', 'DA2', 'DB1', 'DB2', 'DDR1', 'DDR2', 'AGE_DON', 'COD_CAD_DON', 'DEATH_CIRCUM_DON', 'DEATH_MECH_DON', 'BLOOD_INF_DON', 'BUN_DON', 'CREAT_DON', 'PULM_INF_DON', 'SGOT_DON', 'SGPT_DON', 'TBILI_DON', 'URINE_INF_DON', 'CANCER_SITE_DON', 'HIST_DIABETES_DON', 'HGT_CM_DON_CALC', 'WGT_KG_DON_CALC', 'BMI_DON_CALC', 'ECD_DONOR', 'CREAT_TX', 'TBILI_TX', 'INR_TX', 'ALBUMIN_TX', 'ENCEPH_TX', 'ASCITES_TX', 'MELD_PELD_LAB_SCORE', 'EXC_EVER', 'LITYP', 'LOS', 'AGE', 'DIAG', 'ABO_MAT', 'COLD_ISCH', 'SHARE_TY', 'HGT_CM_CALC', 'WGT_KG_CALC', 'BMI_CALC', 'DONOR_ID', 'TRANSFUS_TERM_DON', 'PH_DON', 'HEMATOCRIT_DON', 'TX_YEAR', 'LISTYR', 'GENDER_F', 'GENDER_M', 'ABO_A', 'ABO_A1', 'ABO_A1B', 'ABO_A2', 'ABO_A2B', 'ABO_AB', 'ABO_B', 'ABO_O', 'EXC_HCC_HBL', 'EXC_HCC_HCC', 'EXC_HCC_non-HCC', 'EXC_CASE_No', 'EXC_CASE_Yes', 'FINAL_DIALYSIS_PRIOR_WEEK_A', 'FINAL_DIALYSIS_PRIOR_WEEK_N', 'FINAL_DIALYSIS_PRIOR_WEEK_Y', 'FINAL_MELD_OR_PELD_MELD', 'FINAL_MELD_OR_PELD_PELD', 'MALIG_TRR_N', 'MALIG_TRR_U', 'PORTAL_VEIN_TRR_N', 'PORTAL_VEIN_TRR_U', 'PORTAL_VEIN_TRR_Y', 'PREV_AB_SURG_TRR_N', 'PREV_AB_SURG_TRR_U', 'PREV_AB_SURG_TRR_Y', 'TIPSS_TRR_N', 'TIPSS_TRR_U', 'TIPSS_TRR_Y', 'HBV_CORE_N', 'HBV_CORE_P', 'HBV_SUR_ANTIGEN_N', 'HBV_SUR_ANTIGEN_ND', 'HBV_SUR_ANTIGEN_P', 'HBV_SUR_ANTIGEN_U', 'HCV_SEROSTATUS_N', 'HCV_SEROSTATUS_P', 'HCV_SEROSTATUS_U', 'EBV_SEROSTATUS_N', 'EBV_SEROSTATUS_ND', 'EBV_SEROSTATUS_P', 'EBV_SEROSTATUS_U', 'HIV_SEROSTATUS_N', 'HIV_SEROSTATUS_U', 'CMV_STATUS_N', 'CMV_STATUS_ND', 'CMV_STATUS_P', 'CMV_STATUS_U', 'CMV_IGG_N', 'CMV_IGG_ND', 'CMV_IGG_P', 'CMV_IGG_U', 'CMV_IGM_N', 'CMV_IGM_ND', 'CMV_IGM_P', 'CMV_IGM_U', 'PREV_TX_N', 'PREV_TX_Y', 'DDAVP_DON_N', 'DDAVP_DON_U', 'DDAVP_DON_Y', 'CMV_DON_I', 'CMV_DON_N', 'CMV_DON_ND', 'CMV_DON_P', 'CMV_DON_U', 'HEP_C_ANTI_DON_N', 'HEP_C_ANTI_DON_ND', 'HEP_C_ANTI_DON_P', 'HEP_C_ANTI_DON_U', 'HBV_CORE_DON_N', 'HBV_CORE_DON_ND', 'HBV_CORE_DON_P', 'HBV_CORE_DON_U', 'HBV_SUR_ANTIGEN_DON_N', 'HBV_SUR_ANTIGEN_DON_ND', 'HBV_SUR_ANTIGEN_DON_P', 'HBV_SUR_ANTIGEN_DON_U', 'DON_TY_C', 'DON_TY_L', 'GENDER_DON_F', 'GENDER_DON_M', 'NON_HRT_DON_N', 'NON_HRT_DON_Y', 'ANTIHYPE_DON_N', 'ANTIHYPE_DON_U', 'PT_DIURETICS_DON_N', 'PT_DIURETICS_DON_U', 'PT_DIURETICS_DON_Y', 'PT_STEROIDS_DON_N', 'PT_STEROIDS_DON_U', 'PT_STEROIDS_DON_Y', 'PT_T3_DON_U', 'PT_T4_DON_N', 'PT_T4_DON_U', 'PT_T4_DON_Y', 'VASODIL_DON_N', 'VASODIL_DON_U', 'VASODIL_DON_Y', 'VDRL_DON_N', 'VDRL_DON_ND', 'VDRL_DON_P', 'VDRL_DON_U', 'CLIN_INFECT_DON_N', 'CLIN_INFECT_DON_Y', 'EXTRACRANIAL_CANCER_DON_N', 'EXTRACRANIAL_CANCER_DON_U', 'HIST_CIG_DON_N', 'HIST_CIG_DON_U', 'HIST_CIG_DON_Y', 'HIST_COCAINE_DON_N', 'HIST_COCAINE_DON_U', 'HIST_COCAINE_DON_Y', 'DIABETES_DON_N', 'DIABETES_DON_Y', 'HIST_HYPERTENS_DON_N', 'HIST_HYPERTENS_DON_U', 'HIST_HYPERTENS_DON_Y', 'HIST_OTH_DRUG_DON_N', 'HIST_OTH_DRUG_DON_Y', 'ABO_DON_A', 'ABO_DON_A1', 'ABO_DON_A1B', 'ABO_DON_A2', 'ABO_DON_B', 'ABO_DON_O', 'INTRACRANIAL_CANCER_DON_N', 'INTRACRANIAL_CANCER_DON_U', 'INTRACRANIAL_CANCER_DON_Y', 'SKIN_CANCER_DON_U', 'SKIN_CANCER_DON_Y', 'HIST_CANCER_DON_N', 'HIST_CANCER_DON_Y', 'PT_OTH_DON_N', 'PT_OTH_DON_Y', 'HEPARIN_DON_N', 'HEPARIN_DON_U', 'HEPARIN_DON_Y', 'HBV_CORE_DON.1_N', 'HBV_CORE_DON.1_Y', 'INSULIN_DON_N', 'INSULIN_DON_U', 'AGE_GROUP_A', 'AGE_GROUP_P', 'MALIG_N', 'MALIG_U', 'MALIG_Y', 'RECOV_OUT_US_N', 'RECOV_OUT_US_Y', 'TATTOOS_N', 'TATTOOS_U', 'TATTOOS_Y', 'LI_BIOPSY_N', 'LI_BIOPSY_Y', 'PROTEIN_URINE_N', 'PROTEIN_URINE_U', 'PROTEIN_URINE_Y', 'INOTROP_SUPPORT_DON_N', 'INOTROP_SUPPORT_DON_U', 'INOTROP_SUPPORT_DON_Y', 'CDC_RISK_HIV_DON_N', 'CDC_RISK_HIV_DON_Y', 'HISTORY_MI_DON_U', 'HISTORY_MI_DON_Y', 'CORONARY_ANGIO_DON_N', 'CORONARY_ANGIO_DON_Y']\n",
    "\n",
    "#x_test= read from csv, convert to a dataframe, name it x_test\n",
    "x_test= pd.read_csv('x_test.csv')\n",
    "\n",
    "def add_missing_dummy_columns( x_test, xtrain_columns ):\n",
    "    missing_cols = set(xtrain_columns) - set(x_test.columns)\n",
    "    for c in missing_cols:\n",
    "        x_test[c] = 0\n",
    "        \n",
    "def fix_columns(x_test, xtrain_columns ):  \n",
    "    add_missing_dummy_columns( x_test, xtrain_columns )\n",
    "    # make sure we have all the columns we need\n",
    "    assert( set( xtrain_columns ) - set( x_test.columns ) == set())\n",
    "    extra_cols = set( x_test.columns ) - set( xtrain_columns )\n",
    "    x_test = x_test[ xtrain_columns ]\n",
    "    return x_test\n",
    "\n",
    "#Identify categorical and non-categorical\n",
    "x_test_cf = x_test.select_dtypes(include=['object'])\n",
    "x_test_ncf = x_test.select_dtypes(exclude=['object'])\n",
    "\n",
    "#Handle NULL values in categorical features\n",
    "imp_cat = CategoricalImputer()\n",
    "x_test_cf = pd.DataFrame(imp_cat.fit_transform(np.array(x_test_cf)),columns = x_test_cf.columns)\n",
    "\n",
    "#One-hot encoding for categorical features\n",
    "x_test_cfn=pd.get_dummies(x_test_cf)\n",
    "\n",
    "#Handle NULL values in non-categorical features\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(x_test_ncf)\n",
    "x_test_ncf = pd.DataFrame(imp.transform(x_test_ncf),columns = x_test_ncf.columns)\n",
    "\n",
    "#Scale test data\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "header=x_test_ncf.columns\n",
    "x_test_minmax = min_max_scaler.fit_transform(x_test_ncf)\n",
    "x_test_ncf=pd.DataFrame(x_test_minmax,columns=header)\n",
    "\n",
    "#merge categorical and non-categorical features\n",
    "result = pd.merge(x_test_ncf, x_test_cfn,left_index=True,right_index=True)\n",
    "#fix columns\n",
    "result=fix_columns(result,xtrain_columns)\n",
    "\n",
    "#Eliminate less important features\n",
    "less_important_features=['ABO_DON_A2B','ABO_DON_AB','ANTIHYPE_DON_Y','CARDARREST_NEURO_N','CARDARREST_NEURO_Y','CDC_RISK_HIV_DON_U','CLIN_INFECT_DON_U','DATA_TRANSPLANT_Y','DATA_WAITLIST_Y','DIABETES_DON_U','DIAL_TX_N','DIAL_TX_Y','EXTRACRANIAL_CANCER_DON_Y','HBV_CORE_DON.1_U','HBV_CORE_DON_I','HBV_CORE_ND','HBV_CORE_U','HBV_SUR_ANTIGEN_DON_C','HBV_SUR_ANTIGEN_DON_I','HCV_SEROSTATUS_ND','HEP_C_ANTI_DON_C','HEP_C_ANTI_DON_I','HISTORY_MI_DON_N','HIST_CANCER_DON_U','HIST_OTH_DRUG_DON_U','HIV_SEROSTATUS_ND','HIV_SEROSTATUS_P','INSULIN_DON_Y','LIFE_SUP_TRR_N','LIFE_SUP_TRR_Y','LIST_MELD_No','LT_ONE_WEEK_DON_N','MALIG_TRR_Y','PT_T3_DON_N','PT_T3_DON_Y','SKIN_CANCER_DON_N','TXLIV_S','TXLIV_W','TX_MELD_No','VDRL_DON_I']\n",
    "cols = [col for col in result.columns if col not in less_important_features]\n",
    "x_test= result[cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Imbalance in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    27505\n",
       "1.0    11657\n",
       "Name: GSTATUS, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['GSTATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Algorithm for oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm = SMOTE()\n",
    "x_train, y_train = sm.fit_sample(x_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape {}'.format(Counter(y_train)))\n",
    "x_train= pd.DataFrame(x_train)\n",
    "y_train= pd.DataFrame(y_train)\n",
    "\n",
    "\n",
    "result =pd.concat([x_train,y_train],axis=1)\n",
    "result.columns=headers\n",
    "\n",
    "#display(result)\n",
    "\n",
    "x_train = result[[column for column in result.columns if column != 'GSTATUS']]\n",
    "y_train= result[['GSTATUS']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.436\n",
      "recall score: 0.204\n",
      "f1 score: 0.278\n",
      "auc roc score: 0.546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "cvscores = []\n",
    "cv1scores = []\n",
    "cv2scores = []\n",
    "cv3scores= []\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "for i, (train, test) in enumerate(kfold.split(X,Y)):\n",
    "       \n",
    "\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    \n",
    "    # oversampling\n",
    "    sm = SMOTE()\n",
    "    x_train, y_train = sm.fit_sample(X[train], Y[train])\n",
    "\n",
    "    RF_model = RFC()\n",
    "    RF_model.fit(x_train,y_train)\n",
    "    y_pred = RF_model.predict(X[test])\n",
    "\n",
    "    cvscores.append(metrics.precision_score(Y[test], y_pred,average='binary'))\n",
    "    cv1scores.append(metrics.recall_score(Y[test], y_pred,average='binary'))\n",
    "    cv2scores.append(metrics.f1_score(Y[test], y_pred,average='binary'))\n",
    "    cv3scores.append(metrics.roc_auc_score(Y[test], y_pred))\n",
    "    \n",
    "\n",
    "\n",
    "print ('precision score: %.3f' % np.mean(cvscores))\n",
    "print ('recall score: %.3f' % np.mean(cv1scores))\n",
    "print ('f1 score: %.3f' % np.mean(cv2scores))\n",
    "print ('auc roc score: %.3f' % np.mean(cv3scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 0.443\n",
      "recall score: 0.634\n",
      "f1 score: 0.521\n",
      "auc roc score: 0.648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "cvscores = []\n",
    "cv1scores = []\n",
    "cv2scores = []\n",
    "cv3scores= []\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "for i, (train, test) in enumerate(kfold.split(X,Y)):\n",
    "       \n",
    "\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    \n",
    "    # oversampling\n",
    "    sm = SMOTE()\n",
    "    x_train, y_train = sm.fit_sample(X[train], Y[train])\n",
    "\n",
    "    logreg = linear_model.LogisticRegression()\n",
    "    logreg.fit(x_train, y_train)\n",
    "    y_pred =logreg.predict(X[test])\n",
    "\n",
    "    cvscores.append(metrics.precision_score(Y[test], y_pred,average='binary'))\n",
    "    cv1scores.append(metrics.recall_score(Y[test], y_pred,average='binary'))\n",
    "    cv2scores.append(metrics.f1_score(Y[test], y_pred,average='binary'))\n",
    "    cv3scores.append(metrics.roc_auc_score(Y[test], y_pred))\n",
    "    \n",
    "\n",
    "\n",
    "print ('precision score: %.3f' % np.mean(cvscores))\n",
    "print ('recall score: %.3f' % np.mean(cv1scores))\n",
    "print ('f1 score: %.3f' % np.mean(cv2scores))\n",
    "print ('auc roc score: %.3f' % np.mean(cv3scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "49508/49508 [==============================] - 8s 156us/step - loss: 0.6243 - acc: 0.6639\n",
      "Epoch 2/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.5298 - acc: 0.7322\n",
      "Epoch 3/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.4998 - acc: 0.7524\n",
      "Epoch 4/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.4698 - acc: 0.7722\n",
      "Epoch 5/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.4430 - acc: 0.7897\n",
      "Epoch 6/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.4123 - acc: 0.8065\n",
      "Epoch 7/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.3821 - acc: 0.8267\n",
      "Epoch 8/100\n",
      "49508/49508 [==============================] - 7s 150us/step - loss: 0.3558 - acc: 0.8398\n",
      "Epoch 9/100\n",
      "49508/49508 [==============================] - 8s 163us/step - loss: 0.3313 - acc: 0.8537\n",
      "Epoch 10/100\n",
      "49508/49508 [==============================] - 8s 159us/step - loss: 0.3049 - acc: 0.8667\n",
      "Epoch 11/100\n",
      "49508/49508 [==============================] - 8s 165us/step - loss: 0.2813 - acc: 0.8814\n",
      "Epoch 12/100\n",
      "49508/49508 [==============================] - 8s 162us/step - loss: 0.2594 - acc: 0.8907 1s - loss: \n",
      "Epoch 13/100\n",
      "49508/49508 [==============================] - 8s 162us/step - loss: 0.2439 - acc: 0.8987\n",
      "Epoch 14/100\n",
      "49508/49508 [==============================] - 8s 162us/step - loss: 0.2176 - acc: 0.9110\n",
      "Epoch 15/100\n",
      "49508/49508 [==============================] - 8s 161us/step - loss: 0.2085 - acc: 0.9150\n",
      "Epoch 16/100\n",
      "49508/49508 [==============================] - 8s 159us/step - loss: 0.1923 - acc: 0.9224\n",
      "Epoch 17/100\n",
      "49508/49508 [==============================] - 8s 157us/step - loss: 0.1830 - acc: 0.9260\n",
      "Epoch 18/100\n",
      "49508/49508 [==============================] - 8s 160us/step - loss: 0.1735 - acc: 0.9302 2 - ETA: 0s - loss: 0.16\n",
      "Epoch 19/100\n",
      "49508/49508 [==============================] - 8s 160us/step - loss: 0.1610 - acc: 0.9345 1s - l\n",
      "Epoch 20/100\n",
      "49508/49508 [==============================] - 8s 159us/step - loss: 0.1543 - acc: 0.9383\n",
      "Epoch 21/100\n",
      "49508/49508 [==============================] - 8s 164us/step - loss: 0.1445 - acc: 0.9431 1s - loss:\n",
      "Epoch 22/100\n",
      "49508/49508 [==============================] - 8s 159us/step - loss: 0.1380 - acc: 0.9445 4s - loss: 0.1 - ETA: 3s - loss: 0.128 - ETA: 2s - loss:  - ETA: 1s - loss: 0.1335 - ac - ETA: 0s - loss: 0.13\n",
      "Epoch 23/100\n",
      "49508/49508 [==============================] - 8s 163us/step - loss: 0.1346 - acc: 0.9465\n",
      "Epoch 24/100\n",
      "49508/49508 [==============================] - 8s 160us/step - loss: 0.1268 - acc: 0.9505 5s - loss: 0.1086 -  -\n",
      "Epoch 25/100\n",
      "49508/49508 [==============================] - 8s 158us/step - loss: 0.1265 - acc: 0.9502\n",
      "Epoch 26/100\n",
      "49508/49508 [==============================] - 8s 160us/step - loss: 0.1215 - acc: 0.9541 0s - loss: 0.1198 - ac\n",
      "Epoch 27/100\n",
      "49508/49508 [==============================] - 8s 162us/step - loss: 0.1102 - acc: 0.9577\n",
      "Epoch 28/100\n",
      "49508/49508 [==============================] - 8s 158us/step - loss: 0.1048 - acc: 0.9597\n",
      "Epoch 29/100\n",
      "49508/49508 [==============================] - 8s 160us/step - loss: 0.1058 - acc: 0.9590\n",
      "Epoch 30/100\n",
      "49508/49508 [==============================] - 8s 161us/step - loss: 0.1035 - acc: 0.9599\n",
      "Epoch 31/100\n",
      "49508/49508 [==============================] - 8s 170us/step - loss: 0.0992 - acc: 0.9621\n",
      "Epoch 32/100\n",
      "49508/49508 [==============================] - 9s 191us/step - loss: 0.0957 - acc: 0.9636\n",
      "Epoch 33/100\n",
      "49508/49508 [==============================] - 9s 190us/step - loss: 0.0973 - acc: 0.9629\n",
      "Epoch 34/100\n",
      "49508/49508 [==============================] - 10s 192us/step - loss: 0.0927 - acc: 0.9651\n",
      "Epoch 35/100\n",
      "49508/49508 [==============================] - 9s 187us/step - loss: 0.0828 - acc: 0.9694\n",
      "Epoch 36/100\n",
      "49508/49508 [==============================] - 9s 183us/step - loss: 0.0912 - acc: 0.9651\n",
      "Epoch 37/100\n",
      "49508/49508 [==============================] - 9s 186us/step - loss: 0.0915 - acc: 0.9641 0s - loss: 0.0910 - acc: \n",
      "Epoch 38/100\n",
      "49508/49508 [==============================] - 9s 190us/step - loss: 0.0802 - acc: 0.9707\n",
      "Epoch 39/100\n",
      "49508/49508 [==============================] - 9s 190us/step - loss: 0.0784 - acc: 0.9703\n",
      "Epoch 40/100\n",
      "49508/49508 [==============================] - 9s 190us/step - loss: 0.0826 - acc: 0.9687 0s - loss: 0.0826 - acc: 0\n",
      "Epoch 41/100\n",
      "49508/49508 [==============================] - 9s 189us/step - loss: 0.0769 - acc: 0.9709\n",
      "Epoch 42/100\n",
      "49508/49508 [==============================] - 9s 182us/step - loss: 0.0779 - acc: 0.9703\n",
      "Epoch 43/100\n",
      "49508/49508 [==============================] - 8s 157us/step - loss: 0.0739 - acc: 0.9719 1s \n",
      "Epoch 44/100\n",
      "49508/49508 [==============================] - 8s 162us/step - loss: 0.0754 - acc: 0.9721 2s - loss: 0. - ETA: 1s - los\n",
      "Epoch 45/100\n",
      "49508/49508 [==============================] - 8s 163us/step - loss: 0.0693 - acc: 0.9744\n",
      "Epoch 46/100\n",
      "49508/49508 [==============================] - 8s 167us/step - loss: 0.0734 - acc: 0.9721\n",
      "Epoch 47/100\n",
      "49508/49508 [==============================] - 8s 163us/step - loss: 0.0724 - acc: 0.9727 1s - los\n",
      "Epoch 48/100\n",
      "49508/49508 [==============================] - 8s 162us/step - loss: 0.0660 - acc: 0.9756 0s - loss: 0.06\n",
      "Epoch 49/100\n",
      "49508/49508 [==============================] - 8s 162us/step - loss: 0.0667 - acc: 0.9752\n",
      "Epoch 50/100\n",
      "49508/49508 [==============================] - 8s 164us/step - loss: 0.0682 - acc: 0.9745\n",
      "Epoch 51/100\n",
      "49508/49508 [==============================] - 8s 162us/step - loss: 0.0632 - acc: 0.9770\n",
      "Epoch 52/100\n",
      "49508/49508 [==============================] - ETA: 0s - loss: 0.0637 - acc: 0.9766- ETA: 3s - loss: 0.0623 - acc: 0. - ETA: 3 - ETA: 1s - los - 8s 168us/step - loss: 0.0640 - acc: 0.9765\n",
      "Epoch 53/100\n",
      "49508/49508 [==============================] - 8s 169us/step - loss: 0.0638 - acc: 0.9760\n",
      "Epoch 54/100\n",
      "49508/49508 [==============================] - 8s 163us/step - loss: 0.0612 - acc: 0.9768\n",
      "Epoch 55/100\n",
      "49508/49508 [==============================] - 8s 167us/step - loss: 0.0630 - acc: 0.9766\n",
      "Epoch 56/100\n",
      "49508/49508 [==============================] - 8s 163us/step - loss: 0.0620 - acc: 0.9761\n",
      "Epoch 57/100\n",
      "49508/49508 [==============================] - 9s 172us/step - loss: 0.0594 - acc: 0.9778\n",
      "Epoch 58/100\n",
      "49508/49508 [==============================] - 9s 178us/step - loss: 0.0602 - acc: 0.9783\n",
      "Epoch 59/100\n",
      "49508/49508 [==============================] - 9s 186us/step - loss: 0.0552 - acc: 0.9802\n",
      "Epoch 60/100\n",
      "49508/49508 [==============================] - 9s 184us/step - loss: 0.0512 - acc: 0.9810\n",
      "Epoch 61/100\n",
      "49508/49508 [==============================] - 8s 170us/step - loss: 0.0610 - acc: 0.9767TA: 0s - loss: 0.0599 - acc:\n",
      "Epoch 62/100\n",
      "49508/49508 [==============================] - 8s 161us/step - loss: 0.0563 - acc: 0.9795\n",
      "Epoch 63/100\n",
      "49508/49508 [==============================] - 8s 162us/step - loss: 0.0587 - acc: 0.9783 0s - loss: 0.0575 - ac\n",
      "Epoch 64/100\n",
      "49508/49508 [==============================] - 8s 170us/step - loss: 0.0554 - acc: 0.9796\n",
      "Epoch 65/100\n",
      "49508/49508 [==============================] - 8s 169us/step - loss: 0.0531 - acc: 0.9812\n",
      "Epoch 66/100\n",
      "49508/49508 [==============================] - 9s 175us/step - loss: 0.0514 - acc: 0.9808\n",
      "Epoch 67/100\n",
      "49508/49508 [==============================] - 9s 174us/step - loss: 0.0526 - acc: 0.9808\n",
      "Epoch 68/100\n",
      "49508/49508 [==============================] - 8s 169us/step - loss: 0.0498 - acc: 0.9816\n",
      "Epoch 69/100\n",
      "49508/49508 [==============================] - 8s 169us/step - loss: 0.0537 - acc: 0.9800\n",
      "Epoch 70/100\n",
      "49508/49508 [==============================] - 9s 173us/step - loss: 0.0508 - acc: 0.9813 1s \n",
      "Epoch 71/100\n",
      "49508/49508 [==============================] - 9s 172us/step - loss: 0.0465 - acc: 0.9828\n",
      "Epoch 72/100\n",
      "49508/49508 [==============================] - 8s 171us/step - loss: 0.0509 - acc: 0.9807 1s - loss: 0. - ETA: 0s - loss: 0.0505 - acc\n",
      "Epoch 73/100\n",
      "49508/49508 [==============================] - 8s 171us/step - loss: 0.0500 - acc: 0.9816\n",
      "Epoch 74/100\n",
      "49508/49508 [==============================] - 8s 169us/step - loss: 0.0536 - acc: 0.9803 0s - loss: 0.0529 - acc: 0.\n",
      "Epoch 75/100\n",
      "49508/49508 [==============================] - 8s 170us/step - loss: 0.0491 - acc: 0.9821\n",
      "Epoch 76/100\n",
      "49508/49508 [==============================] - 8s 169us/step - loss: 0.0441 - acc: 0.9832\n",
      "Epoch 77/100\n",
      "49508/49508 [==============================] - 9s 173us/step - loss: 0.0445 - acc: 0.9841\n",
      "Epoch 78/100\n",
      "49508/49508 [==============================] - 8s 170us/step - loss: 0.0496 - acc: 0.9812\n",
      "Epoch 79/100\n",
      "49508/49508 [==============================] - 8s 168us/step - loss: 0.0490 - acc: 0.9817 1s\n",
      "Epoch 80/100\n",
      "49508/49508 [==============================] - 8s 171us/step - loss: 0.0442 - acc: 0.9840\n",
      "Epoch 81/100\n",
      "49508/49508 [==============================] - 8s 171us/step - loss: 0.0443 - acc: 0.9838 3s - loss: \n",
      "Epoch 82/100\n",
      "49508/49508 [==============================] - 8s 169us/step - loss: 0.0439 - acc: 0.9842 1s - loss:\n",
      "Epoch 83/100\n",
      "49508/49508 [==============================] - 8s 172us/step - loss: 0.0448 - acc: 0.9837\n",
      "Epoch 84/100\n",
      "49508/49508 [==============================] - 9s 177us/step - loss: 0.0473 - acc: 0.9828\n",
      "Epoch 85/100\n",
      "49508/49508 [==============================] - 9s 179us/step - loss: 0.0397 - acc: 0.9861\n",
      "Epoch 86/100\n",
      "49508/49508 [==============================] - 9s 177us/step - loss: 0.0421 - acc: 0.9846\n",
      "Epoch 87/100\n",
      "49508/49508 [==============================] - 9s 179us/step - loss: 0.0436 - acc: 0.9839\n",
      "Epoch 88/100\n",
      "49508/49508 [==============================] - 9s 178us/step - loss: 0.0453 - acc: 0.9832\n",
      "Epoch 89/100\n",
      "49508/49508 [==============================] - 9s 175us/step - loss: 0.0401 - acc: 0.9857\n",
      "Epoch 90/100\n",
      "49508/49508 [==============================] - 9s 178us/step - loss: 0.0390 - acc: 0.9860 \n",
      "Epoch 91/100\n",
      "49508/49508 [==============================] - 9s 178us/step - loss: 0.0400 - acc: 0.9849 1\n",
      "Epoch 92/100\n",
      "49508/49508 [==============================] - 9s 177us/step - loss: 0.0426 - acc: 0.9850 2s - loss: 0.0417 - acc: 0 \n",
      "Epoch 93/100\n",
      "49508/49508 [==============================] - 8s 170us/step - loss: 0.0419 - acc: 0.9851\n",
      "Epoch 94/100\n",
      "49508/49508 [==============================] - 9s 174us/step - loss: 0.0386 - acc: 0.9858\n",
      "Epoch 95/100\n",
      "49508/49508 [==============================] - 9s 177us/step - loss: 0.0411 - acc: 0.9844 2s - ETA: 0s - loss: 0.0412 \n",
      "Epoch 96/100\n",
      "49508/49508 [==============================] - 8s 170us/step - loss: 0.0367 - acc: 0.9865\n",
      "Epoch 97/100\n",
      "49508/49508 [==============================] - 8s 168us/step - loss: 0.0415 - acc: 0.9854\n",
      "Epoch 98/100\n",
      "49508/49508 [==============================] - 9s 179us/step - loss: 0.0354 - acc: 0.9872\n",
      "Epoch 99/100\n",
      "49508/49508 [==============================] - 9s 180us/step - loss: 0.0410 - acc: 0.9849\n",
      "Epoch 100/100\n",
      "49508/49508 [==============================] - 9s 176us/step - loss: 0.0367 - acc: 0.9866\n",
      "Epoch 1/100\n",
      "49508/49508 [==============================] - 8s 167us/step - loss: 0.6090 - acc: 0.6726\n",
      "Epoch 2/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.5266 - acc: 0.7353\n",
      "Epoch 3/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.4889 - acc: 0.7623\n",
      "Epoch 4/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.4594 - acc: 0.7774\n",
      "Epoch 5/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.4277 - acc: 0.7957\n",
      "Epoch 6/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.3987 - acc: 0.8152\n",
      "Epoch 7/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.3764 - acc: 0.8291\n",
      "Epoch 8/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.3525 - acc: 0.8413\n",
      "Epoch 9/100\n",
      "49508/49508 [==============================] - 6s 131us/step - loss: 0.3270 - acc: 0.8557\n",
      "Epoch 10/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.3066 - acc: 0.8652\n",
      "Epoch 11/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.2792 - acc: 0.8802\n",
      "Epoch 12/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.2633 - acc: 0.8882\n",
      "Epoch 13/100\n",
      "49508/49508 [==============================] - 6s 128us/step - loss: 0.2402 - acc: 0.8993\n",
      "Epoch 14/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.2232 - acc: 0.9055\n",
      "Epoch 15/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.2077 - acc: 0.9144\n",
      "Epoch 16/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1930 - acc: 0.9212\n",
      "Epoch 17/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1829 - acc: 0.9267\n",
      "Epoch 18/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1687 - acc: 0.9317\n",
      "Epoch 19/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.1593 - acc: 0.9369\n",
      "Epoch 20/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1496 - acc: 0.9409\n",
      "Epoch 21/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1447 - acc: 0.9431\n",
      "Epoch 22/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1395 - acc: 0.9451\n",
      "Epoch 23/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1256 - acc: 0.9503\n",
      "Epoch 24/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1250 - acc: 0.9500\n",
      "Epoch 25/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.1222 - acc: 0.9528\n",
      "Epoch 26/100\n",
      "49508/49508 [==============================] - 6s 126us/step - loss: 0.1130 - acc: 0.9564\n",
      "Epoch 27/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1139 - acc: 0.9566\n",
      "Epoch 28/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1057 - acc: 0.9596\n",
      "Epoch 29/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1054 - acc: 0.9599\n",
      "Epoch 30/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.1034 - acc: 0.9603 0s - loss: 0.10\n",
      "Epoch 31/100\n",
      "49508/49508 [==============================] - 6s 126us/step - loss: 0.1021 - acc: 0.9606 4s - loss: 0.0862 - - ETA: 3s  - ETA: 1s\n",
      "Epoch 32/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.0948 - acc: 0.9640\n",
      "Epoch 33/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.0966 - acc: 0.9626\n",
      "Epoch 34/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.0873 - acc: 0.9662\n",
      "Epoch 35/100\n",
      "49508/49508 [==============================] - 7s 132us/step - loss: 0.0880 - acc: 0.9668\n",
      "Epoch 36/100\n",
      "49508/49508 [==============================] - 10s 192us/step - loss: 0.0912 - acc: 0.9658\n",
      "Epoch 37/100\n",
      "49508/49508 [==============================] - 9s 189us/step - loss: 0.0876 - acc: 0.9667 1s - l\n",
      "Epoch 38/100\n",
      "49508/49508 [==============================] - 10s 194us/step - loss: 0.0786 - acc: 0.9706\n",
      "Epoch 39/100\n",
      "49508/49508 [==============================] - 10s 192us/step - loss: 0.0879 - acc: 0.9659\n",
      "Epoch 40/100\n",
      "49508/49508 [==============================] - 9s 191us/step - loss: 0.0788 - acc: 0.9703\n",
      "Epoch 41/100\n",
      "49508/49508 [==============================] - 9s 189us/step - loss: 0.0767 - acc: 0.9714\n",
      "Epoch 42/100\n",
      "49508/49508 [==============================] - 9s 176us/step - loss: 0.0780 - acc: 0.9717\n",
      "Epoch 43/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.0786 - acc: 0.9707\n",
      "Epoch 44/100\n",
      "49508/49508 [==============================] - 5s 108us/step - loss: 0.0722 - acc: 0.9735\n",
      "Epoch 45/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0725 - acc: 0.9730\n",
      "Epoch 46/100\n",
      "49508/49508 [==============================] - 3171s 64ms/step - loss: 0.0754 - acc: 0.9708\n",
      "Epoch 47/100\n",
      "49508/49508 [==============================] - 6s 128us/step - loss: 0.0709 - acc: 0.9738\n",
      "Epoch 48/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0685 - acc: 0.9741 1s - loss:  - ETA: 0s - loss: 0.0671 - \n",
      "Epoch 49/100\n",
      "49508/49508 [==============================] - 6s 125us/step - loss: 0.0688 - acc: 0.9743\n",
      "Epoch 50/100\n",
      "49508/49508 [==============================] - 6s 125us/step - loss: 0.0675 - acc: 0.9755 0s - loss: 0.0662 - \n",
      "Epoch 51/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0684 - acc: 0.9748\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0652 - acc: 0.9762\n",
      "Epoch 53/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0634 - acc: 0.9762\n",
      "Epoch 54/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.0660 - acc: 0.9757\n",
      "Epoch 55/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0586 - acc: 0.9780 3s -\n",
      "Epoch 56/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0611 - acc: 0.9767\n",
      "Epoch 57/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.0605 - acc: 0.9770\n",
      "Epoch 58/100\n",
      "49508/49508 [==============================] - 6s 125us/step - loss: 0.0592 - acc: 0.9781\n",
      "Epoch 59/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0604 - acc: 0.9771\n",
      "Epoch 60/100\n",
      "49508/49508 [==============================] - 6s 127us/step - loss: 0.0608 - acc: 0.9774 1s - loss: 0.0 - ETA: 0s - loss: 0.0601 - acc: \n",
      "Epoch 61/100\n",
      "49508/49508 [==============================] - 6s 126us/step - loss: 0.0542 - acc: 0.9799\n",
      "Epoch 62/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0501 - acc: 0.9821\n",
      "Epoch 63/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0583 - acc: 0.9779\n",
      "Epoch 64/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0557 - acc: 0.9795\n",
      "Epoch 65/100\n",
      "49508/49508 [==============================] - 6s 128us/step - loss: 0.0539 - acc: 0.9803\n",
      "Epoch 66/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0515 - acc: 0.9805\n",
      "Epoch 67/100\n",
      "49508/49508 [==============================] - 6s 111us/step - loss: 0.0535 - acc: 0.9808\n",
      "Epoch 68/100\n",
      "49508/49508 [==============================] - 6s 111us/step - loss: 0.0521 - acc: 0.9802\n",
      "Epoch 69/100\n",
      "49508/49508 [==============================] - 5s 111us/step - loss: 0.0576 - acc: 0.9787\n",
      "Epoch 70/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.0519 - acc: 0.9808\n",
      "Epoch 71/100\n",
      "49508/49508 [==============================] - 6s 125us/step - loss: 0.0518 - acc: 0.9805\n",
      "Epoch 72/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0485 - acc: 0.9825\n",
      "Epoch 73/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.0536 - acc: 0.9804\n",
      "Epoch 74/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.0532 - acc: 0.9803\n",
      "Epoch 75/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.0504 - acc: 0.9823\n",
      "Epoch 76/100\n",
      "49508/49508 [==============================] - 5s 109us/step - loss: 0.0486 - acc: 0.9824\n",
      "Epoch 77/100\n",
      "49508/49508 [==============================] - 5s 109us/step - loss: 0.0496 - acc: 0.9824\n",
      "Epoch 78/100\n",
      "49508/49508 [==============================] - 5s 110us/step - loss: 0.0476 - acc: 0.9826\n",
      "Epoch 79/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.0469 - acc: 0.9824\n",
      "Epoch 80/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.0503 - acc: 0.9814 5s - lo - - ETA: 1s - loss:\n",
      "Epoch 81/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0466 - acc: 0.9831\n",
      "Epoch 82/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0481 - acc: 0.9822\n",
      "Epoch 83/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0437 - acc: 0.9845\n",
      "Epoch 84/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0433 - acc: 0.9838\n",
      "Epoch 85/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.0444 - acc: 0.9843\n",
      "Epoch 86/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0418 - acc: 0.9846\n",
      "Epoch 87/100\n",
      "49508/49508 [==============================] - 6s 111us/step - loss: 0.0432 - acc: 0.9839\n",
      "Epoch 88/100\n",
      "49508/49508 [==============================] - 5s 110us/step - loss: 0.0473 - acc: 0.9829\n",
      "Epoch 89/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.0418 - acc: 0.9850\n",
      "Epoch 90/100\n",
      "49508/49508 [==============================] - 5s 111us/step - loss: 0.0377 - acc: 0.9860\n",
      "Epoch 91/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.0463 - acc: 0.9828\n",
      "Epoch 92/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0439 - acc: 0.9839\n",
      "Epoch 93/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.0412 - acc: 0.9852\n",
      "Epoch 94/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0390 - acc: 0.9861\n",
      "Epoch 95/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.0396 - acc: 0.9860\n",
      "Epoch 96/100\n",
      "49508/49508 [==============================] - 5s 110us/step - loss: 0.0402 - acc: 0.9852\n",
      "Epoch 97/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0386 - acc: 0.9861\n",
      "Epoch 98/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0365 - acc: 0.9869 2s - loss: 0.0338 - - ETA: 1s - los\n",
      "Epoch 99/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0393 - acc: 0.9864\n",
      "Epoch 100/100\n",
      "49508/49508 [==============================] - 5s 111us/step - loss: 0.0399 - acc: 0.9857\n",
      "Epoch 1/100\n",
      "49508/49508 [==============================] - 9s 178us/step - loss: 0.6106 - acc: 0.6714\n",
      "Epoch 2/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.5296 - acc: 0.7293\n",
      "Epoch 3/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.4983 - acc: 0.7523\n",
      "Epoch 4/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.4689 - acc: 0.7716\n",
      "Epoch 5/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.4469 - acc: 0.7870\n",
      "Epoch 6/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.4205 - acc: 0.8010\n",
      "Epoch 7/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.3914 - acc: 0.8188\n",
      "Epoch 8/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.3603 - acc: 0.8351\n",
      "Epoch 9/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.3391 - acc: 0.8484\n",
      "Epoch 10/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.3152 - acc: 0.8618\n",
      "Epoch 11/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.2925 - acc: 0.8738 0s - loss: 0.2886 - \n",
      "Epoch 12/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.2717 - acc: 0.8836\n",
      "Epoch 13/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.2524 - acc: 0.8951\n",
      "Epoch 14/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.2351 - acc: 0.9007\n",
      "Epoch 15/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.2151 - acc: 0.9120\n",
      "Epoch 16/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.2079 - acc: 0.9148\n",
      "Epoch 17/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.1871 - acc: 0.9250\n",
      "Epoch 18/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.1775 - acc: 0.9288\n",
      "Epoch 19/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.1643 - acc: 0.9341\n",
      "Epoch 20/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.1617 - acc: 0.9365\n",
      "Epoch 21/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.1463 - acc: 0.9432\n",
      "Epoch 22/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.1416 - acc: 0.9436\n",
      "Epoch 23/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.1388 - acc: 0.9437\n",
      "Epoch 24/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.1250 - acc: 0.9518\n",
      "Epoch 25/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.1286 - acc: 0.9499\n",
      "Epoch 26/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.1206 - acc: 0.9536\n",
      "Epoch 27/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.1181 - acc: 0.9538\n",
      "Epoch 28/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.1128 - acc: 0.9567\n",
      "Epoch 29/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.1077 - acc: 0.9586\n",
      "Epoch 30/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.1103 - acc: 0.9564\n",
      "Epoch 31/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.1084 - acc: 0.9581\n",
      "Epoch 32/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0964 - acc: 0.9634\n",
      "Epoch 33/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0927 - acc: 0.9643\n",
      "Epoch 34/100\n",
      "49508/49508 [==============================] - 4s 86us/step - loss: 0.1006 - acc: 0.9610\n",
      "Epoch 35/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0915 - acc: 0.9649\n",
      "Epoch 36/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0887 - acc: 0.9662\n",
      "Epoch 37/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0951 - acc: 0.9633\n",
      "Epoch 38/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0834 - acc: 0.9690\n",
      "Epoch 39/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0840 - acc: 0.9684\n",
      "Epoch 40/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0773 - acc: 0.9713\n",
      "Epoch 41/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0896 - acc: 0.9658\n",
      "Epoch 42/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0800 - acc: 0.9697\n",
      "Epoch 43/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0853 - acc: 0.9672\n",
      "Epoch 44/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.0825 - acc: 0.9689\n",
      "Epoch 45/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0787 - acc: 0.9705\n",
      "Epoch 46/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0654 - acc: 0.9755\n",
      "Epoch 47/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0738 - acc: 0.9720\n",
      "Epoch 48/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0763 - acc: 0.9715\n",
      "Epoch 49/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0694 - acc: 0.9740\n",
      "Epoch 50/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0706 - acc: 0.9727\n",
      "Epoch 51/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0719 - acc: 0.9733\n",
      "Epoch 52/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.0670 - acc: 0.9756\n",
      "Epoch 53/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0683 - acc: 0.9745\n",
      "Epoch 54/100\n",
      "49508/49508 [==============================] - 4s 86us/step - loss: 0.0620 - acc: 0.9768\n",
      "Epoch 55/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0690 - acc: 0.9741\n",
      "Epoch 56/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0633 - acc: 0.9765\n",
      "Epoch 57/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0644 - acc: 0.9754\n",
      "Epoch 58/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.0656 - acc: 0.9754: \n",
      "Epoch 59/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0611 - acc: 0.9776\n",
      "Epoch 60/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0629 - acc: 0.9761\n",
      "Epoch 61/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.0561 - acc: 0.9789\n",
      "Epoch 62/100\n",
      "49508/49508 [==============================] - 4s 80us/step - loss: 0.0576 - acc: 0.9784\n",
      "Epoch 63/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.0617 - acc: 0.9772\n",
      "Epoch 64/100\n",
      "49508/49508 [==============================] - 4s 91us/step - loss: 0.0583 - acc: 0.9786\n",
      "Epoch 65/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0556 - acc: 0.9793\n",
      "Epoch 66/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0563 - acc: 0.9784\n",
      "Epoch 67/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0528 - acc: 0.9806\n",
      "Epoch 68/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0529 - acc: 0.9811\n",
      "Epoch 69/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0574 - acc: 0.9782\n",
      "Epoch 70/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0536 - acc: 0.9804\n",
      "Epoch 71/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.0488 - acc: 0.9825\n",
      "Epoch 72/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0511 - acc: 0.9805\n",
      "Epoch 73/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0562 - acc: 0.9789\n",
      "Epoch 74/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0533 - acc: 0.9807\n",
      "Epoch 75/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0487 - acc: 0.9825\n",
      "Epoch 76/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0535 - acc: 0.9809\n",
      "Epoch 77/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0457 - acc: 0.9832\n",
      "Epoch 78/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0483 - acc: 0.9825\n",
      "Epoch 79/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0531 - acc: 0.9800\n",
      "Epoch 80/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0483 - acc: 0.9818\n",
      "Epoch 81/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0471 - acc: 0.9826\n",
      "Epoch 82/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.0494 - acc: 0.9812\n",
      "Epoch 83/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0438 - acc: 0.9840\n",
      "Epoch 84/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0456 - acc: 0.9835\n",
      "Epoch 85/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0454 - acc: 0.9832\n",
      "Epoch 86/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0455 - acc: 0.9835\n",
      "Epoch 87/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0421 - acc: 0.9848\n",
      "Epoch 88/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0460 - acc: 0.9832\n",
      "Epoch 89/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0470 - acc: 0.9829\n",
      "Epoch 90/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0442 - acc: 0.9840\n",
      "Epoch 91/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0404 - acc: 0.9857\n",
      "Epoch 92/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0421 - acc: 0.9845\n",
      "Epoch 93/100\n",
      "49508/49508 [==============================] - 6s 127us/step - loss: 0.0412 - acc: 0.9847\n",
      "Epoch 94/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0418 - acc: 0.9845\n",
      "Epoch 95/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.0414 - acc: 0.9853\n",
      "Epoch 96/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0425 - acc: 0.9846\n",
      "Epoch 97/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0414 - acc: 0.9845\n",
      "Epoch 98/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0373 - acc: 0.9858\n",
      "Epoch 99/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0419 - acc: 0.9841\n",
      "Epoch 100/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0417 - acc: 0.9845\n",
      "Epoch 1/100\n",
      "49508/49508 [==============================] - 9s 185us/step - loss: 0.6181 - acc: 0.6619\n",
      "Epoch 2/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.5336 - acc: 0.7285\n",
      "Epoch 3/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.4993 - acc: 0.7527\n",
      "Epoch 4/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.4623 - acc: 0.7776\n",
      "Epoch 5/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.4368 - acc: 0.7941\n",
      "Epoch 6/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.4024 - acc: 0.8136\n",
      "Epoch 7/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.3796 - acc: 0.8248\n",
      "Epoch 8/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.3553 - acc: 0.8398\n",
      "Epoch 9/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.3341 - acc: 0.8532\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.3053 - acc: 0.8669\n",
      "Epoch 11/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.2823 - acc: 0.8775\n",
      "Epoch 12/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.2636 - acc: 0.8878\n",
      "Epoch 13/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.2511 - acc: 0.8932\n",
      "Epoch 14/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.2244 - acc: 0.9064\n",
      "Epoch 15/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.2128 - acc: 0.9120\n",
      "Epoch 16/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.1960 - acc: 0.9188\n",
      "Epoch 17/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.1859 - acc: 0.9248\n",
      "Epoch 18/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.1773 - acc: 0.9281\n",
      "Epoch 19/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.1687 - acc: 0.9320\n",
      "Epoch 20/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.1572 - acc: 0.9376\n",
      "Epoch 21/100\n",
      "49508/49508 [==============================] - 6s 125us/step - loss: 0.1472 - acc: 0.9409 0s - loss: 0.1424 \n",
      "Epoch 22/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.1394 - acc: 0.9451\n",
      "Epoch 23/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.1405 - acc: 0.9450\n",
      "Epoch 24/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.1257 - acc: 0.9510\n",
      "Epoch 25/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.1280 - acc: 0.9499\n",
      "Epoch 26/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.1220 - acc: 0.9522\n",
      "Epoch 27/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.1214 - acc: 0.9529\n",
      "Epoch 28/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.1131 - acc: 0.9560 3s - loss\n",
      "Epoch 29/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.1112 - acc: 0.9573 1s -\n",
      "Epoch 30/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.1104 - acc: 0.9566\n",
      "Epoch 31/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.1074 - acc: 0.9580\n",
      "Epoch 32/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.1035 - acc: 0.9595\n",
      "Epoch 33/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.0955 - acc: 0.9641\n",
      "Epoch 34/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0966 - acc: 0.9631\n",
      "Epoch 35/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0909 - acc: 0.9653\n",
      "Epoch 36/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0924 - acc: 0.9650\n",
      "Epoch 37/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0869 - acc: 0.9669\n",
      "Epoch 38/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.0886 - acc: 0.9671\n",
      "Epoch 39/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0843 - acc: 0.9679\n",
      "Epoch 40/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0840 - acc: 0.9685\n",
      "Epoch 41/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0819 - acc: 0.9694\n",
      "Epoch 42/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0840 - acc: 0.9678\n",
      "Epoch 43/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0801 - acc: 0.9701\n",
      "Epoch 44/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0783 - acc: 0.9700\n",
      "Epoch 45/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0749 - acc: 0.9719\n",
      "Epoch 46/100\n",
      "49508/49508 [==============================] - 6s 112us/step - loss: 0.0776 - acc: 0.9709\n",
      "Epoch 47/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0709 - acc: 0.9734\n",
      "Epoch 48/100\n",
      "49508/49508 [==============================] - 4s 86us/step - loss: 0.0730 - acc: 0.9730\n",
      "Epoch 49/100\n",
      "49508/49508 [==============================] - 4s 86us/step - loss: 0.0706 - acc: 0.9734\n",
      "Epoch 50/100\n",
      "49508/49508 [==============================] - 4s 86us/step - loss: 0.0704 - acc: 0.9728\n",
      "Epoch 51/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0684 - acc: 0.9746\n",
      "Epoch 52/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0666 - acc: 0.9756\n",
      "Epoch 53/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0663 - acc: 0.9749\n",
      "Epoch 54/100\n",
      "49508/49508 [==============================] - 4s 87us/step - loss: 0.0630 - acc: 0.9768\n",
      "Epoch 55/100\n",
      "49508/49508 [==============================] - 4s 90us/step - loss: 0.0640 - acc: 0.9761\n",
      "Epoch 56/100\n",
      "49508/49508 [==============================] - 4s 89us/step - loss: 0.0707 - acc: 0.9733\n",
      "Epoch 57/100\n",
      "49508/49508 [==============================] - 4s 87us/step - loss: 0.0632 - acc: 0.9771\n",
      "Epoch 58/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0639 - acc: 0.9756\n",
      "Epoch 59/100\n",
      "49508/49508 [==============================] - 4s 89us/step - loss: 0.0612 - acc: 0.9774\n",
      "Epoch 60/100\n",
      "49508/49508 [==============================] - 5s 92us/step - loss: 0.0609 - acc: 0.9775\n",
      "Epoch 61/100\n",
      "49508/49508 [==============================] - 4s 88us/step - loss: 0.0566 - acc: 0.9792\n",
      "Epoch 62/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0584 - acc: 0.9787\n",
      "Epoch 63/100\n",
      "49508/49508 [==============================] - 4s 90us/step - loss: 0.0616 - acc: 0.9772\n",
      "Epoch 64/100\n",
      "49508/49508 [==============================] - 4s 87us/step - loss: 0.0599 - acc: 0.9778\n",
      "Epoch 65/100\n",
      "49508/49508 [==============================] - 4s 88us/step - loss: 0.0580 - acc: 0.9791\n",
      "Epoch 66/100\n",
      "49508/49508 [==============================] - 5s 96us/step - loss: 0.0523 - acc: 0.9807: \n",
      "Epoch 67/100\n",
      "49508/49508 [==============================] - 5s 103us/step - loss: 0.0546 - acc: 0.9796\n",
      "Epoch 68/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0592 - acc: 0.9782\n",
      "Epoch 69/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0502 - acc: 0.9816\n",
      "Epoch 70/100\n",
      "49508/49508 [==============================] - 5s 94us/step - loss: 0.0507 - acc: 0.9809\n",
      "Epoch 71/100\n",
      "49508/49508 [==============================] - 4s 86us/step - loss: 0.0595 - acc: 0.9783\n",
      "Epoch 72/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0539 - acc: 0.9799\n",
      "Epoch 73/100\n",
      "49508/49508 [==============================] - 4s 90us/step - loss: 0.0505 - acc: 0.9815\n",
      "Epoch 74/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0513 - acc: 0.9814\n",
      "Epoch 75/100\n",
      "49508/49508 [==============================] - 4s 86us/step - loss: 0.0511 - acc: 0.9806\n",
      "Epoch 76/100\n",
      "49508/49508 [==============================] - 5s 93us/step - loss: 0.0499 - acc: 0.9817\n",
      "Epoch 77/100\n",
      "49508/49508 [==============================] - 4s 87us/step - loss: 0.0500 - acc: 0.9823\n",
      "Epoch 78/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.0453 - acc: 0.9837\n",
      "Epoch 79/100\n",
      "49508/49508 [==============================] - 4s 86us/step - loss: 0.0505 - acc: 0.9811\n",
      "Epoch 80/100\n",
      "49508/49508 [==============================] - 5s 91us/step - loss: 0.0501 - acc: 0.9817\n",
      "Epoch 81/100\n",
      "49508/49508 [==============================] - 4s 88us/step - loss: 0.0471 - acc: 0.9826\n",
      "Epoch 82/100\n",
      "49508/49508 [==============================] - 4s 87us/step - loss: 0.0435 - acc: 0.9844\n",
      "Epoch 83/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0494 - acc: 0.9826\n",
      "Epoch 84/100\n",
      "49508/49508 [==============================] - 5s 100us/step - loss: 0.0459 - acc: 0.9834\n",
      "Epoch 85/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0433 - acc: 0.9850\n",
      "Epoch 86/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.0448 - acc: 0.9833\n",
      "Epoch 87/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.0436 - acc: 0.9845\n",
      "Epoch 88/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0477 - acc: 0.9830\n",
      "Epoch 89/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0448 - acc: 0.9831\n",
      "Epoch 90/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0424 - acc: 0.9851\n",
      "Epoch 91/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0442 - acc: 0.9839\n",
      "Epoch 92/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0430 - acc: 0.9846\n",
      "Epoch 93/100\n",
      "49508/49508 [==============================] - 7s 131us/step - loss: 0.0420 - acc: 0.9848\n",
      "Epoch 94/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0438 - acc: 0.9837\n",
      "Epoch 95/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0400 - acc: 0.9850\n",
      "Epoch 96/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0429 - acc: 0.9843\n",
      "Epoch 97/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0382 - acc: 0.9860\n",
      "Epoch 98/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0375 - acc: 0.9863\n",
      "Epoch 99/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0418 - acc: 0.9843\n",
      "Epoch 100/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0422 - acc: 0.9846\n",
      "Epoch 1/100\n",
      "49508/49508 [==============================] - 10s 205us/step - loss: 0.6028 - acc: 0.6732\n",
      "Epoch 2/100\n",
      "49508/49508 [==============================] - 6s 124us/step - loss: 0.5303 - acc: 0.7289\n",
      "Epoch 3/100\n",
      "49508/49508 [==============================] - 6s 129us/step - loss: 0.4967 - acc: 0.7526\n",
      "Epoch 4/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.4617 - acc: 0.7750\n",
      "Epoch 5/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.4266 - acc: 0.7989\n",
      "Epoch 6/100\n",
      "49508/49508 [==============================] - 7s 133us/step - loss: 0.4006 - acc: 0.8134\n",
      "Epoch 7/100\n",
      "49508/49508 [==============================] - 6s 131us/step - loss: 0.3738 - acc: 0.8297\n",
      "Epoch 8/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.3534 - acc: 0.8415\n",
      "Epoch 9/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.3234 - acc: 0.8588\n",
      "Epoch 10/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.2998 - acc: 0.8706\n",
      "Epoch 11/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.2811 - acc: 0.8800\n",
      "Epoch 12/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.2548 - acc: 0.8937\n",
      "Epoch 13/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.2382 - acc: 0.9012\n",
      "Epoch 14/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.2202 - acc: 0.9093\n",
      "Epoch 15/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.2024 - acc: 0.9184\n",
      "Epoch 16/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.1873 - acc: 0.9245\n",
      "Epoch 17/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.1743 - acc: 0.9299\n",
      "Epoch 18/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.1691 - acc: 0.9310\n",
      "Epoch 19/100\n",
      "49508/49508 [==============================] - 6s 127us/step - loss: 0.1573 - acc: 0.9378\n",
      "Epoch 20/100\n",
      "49508/49508 [==============================] - 7s 133us/step - loss: 0.1470 - acc: 0.9423\n",
      "Epoch 21/100\n",
      "49508/49508 [==============================] - 6s 131us/step - loss: 0.1458 - acc: 0.9423\n",
      "Epoch 22/100\n",
      "49508/49508 [==============================] - 7s 134us/step - loss: 0.1311 - acc: 0.9491\n",
      "Epoch 23/100\n",
      "49508/49508 [==============================] - 6s 127us/step - loss: 0.1272 - acc: 0.9498\n",
      "Epoch 24/100\n",
      "49508/49508 [==============================] - 7s 132us/step - loss: 0.1224 - acc: 0.9526\n",
      "Epoch 25/100\n",
      "49508/49508 [==============================] - 7s 137us/step - loss: 0.1163 - acc: 0.9552\n",
      "Epoch 26/100\n",
      "49508/49508 [==============================] - 6s 126us/step - loss: 0.1146 - acc: 0.9551\n",
      "Epoch 27/100\n",
      "49508/49508 [==============================] - 6s 124us/step - loss: 0.1093 - acc: 0.9586\n",
      "Epoch 28/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.1116 - acc: 0.9570\n",
      "Epoch 29/100\n",
      "49508/49508 [==============================] - 6s 126us/step - loss: 0.1044 - acc: 0.9593\n",
      "Epoch 30/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.1003 - acc: 0.9616\n",
      "Epoch 31/100\n",
      "49508/49508 [==============================] - 6s 127us/step - loss: 0.0989 - acc: 0.9619\n",
      "Epoch 32/100\n",
      "49508/49508 [==============================] - 6s 128us/step - loss: 0.0976 - acc: 0.9623\n",
      "Epoch 33/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0932 - acc: 0.9648 0s - loss: 0.090\n",
      "Epoch 34/100\n",
      "49508/49508 [==============================] - 6s 130us/step - loss: 0.0874 - acc: 0.9669 0s - loss: 0.0832 -\n",
      "Epoch 35/100\n",
      "49508/49508 [==============================] - 6s 116us/step - loss: 0.0914 - acc: 0.9642\n",
      "Epoch 36/100\n",
      "49508/49508 [==============================] - 6s 114us/step - loss: 0.0855 - acc: 0.9678\n",
      "Epoch 37/100\n",
      "49508/49508 [==============================] - 6s 115us/step - loss: 0.0868 - acc: 0.9669\n",
      "Epoch 38/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.0773 - acc: 0.9711\n",
      "Epoch 39/100\n",
      "49508/49508 [==============================] - 6s 113us/step - loss: 0.0798 - acc: 0.9699\n",
      "Epoch 40/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0820 - acc: 0.9691\n",
      "Epoch 41/100\n",
      "49508/49508 [==============================] - 6s 125us/step - loss: 0.0753 - acc: 0.9712\n",
      "Epoch 42/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0770 - acc: 0.9711\n",
      "Epoch 43/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0742 - acc: 0.9725 0s - loss: 0.0732 - ac\n",
      "Epoch 44/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0780 - acc: 0.9701\n",
      "Epoch 45/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0702 - acc: 0.9738\n",
      "Epoch 46/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0711 - acc: 0.9724\n",
      "Epoch 47/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0682 - acc: 0.9740\n",
      "Epoch 48/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0700 - acc: 0.9730\n",
      "Epoch 49/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0698 - acc: 0.9743\n",
      "Epoch 50/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0663 - acc: 0.9742\n",
      "Epoch 51/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0633 - acc: 0.9767\n",
      "Epoch 52/100\n",
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0679 - acc: 0.9752\n",
      "Epoch 53/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.0566 - acc: 0.9797\n",
      "Epoch 54/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0641 - acc: 0.9752\n",
      "Epoch 55/100\n",
      "49508/49508 [==============================] - 6s 125us/step - loss: 0.0649 - acc: 0.9764 1s - l\n",
      "Epoch 56/100\n",
      "49508/49508 [==============================] - 6s 121us/step - loss: 0.0565 - acc: 0.9797\n",
      "Epoch 57/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.0595 - acc: 0.9780\n",
      "Epoch 58/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.0583 - acc: 0.9787\n",
      "Epoch 59/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0576 - acc: 0.9792\n",
      "Epoch 60/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0593 - acc: 0.9783\n",
      "Epoch 61/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0571 - acc: 0.9786\n",
      "Epoch 62/100\n",
      "49508/49508 [==============================] - 6s 123us/step - loss: 0.0579 - acc: 0.9784\n",
      "Epoch 63/100\n",
      "49508/49508 [==============================] - 6s 117us/step - loss: 0.0545 - acc: 0.9791 2s  - ETA: 1s - loss\n",
      "Epoch 64/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0548 - acc: 0.9800\n",
      "Epoch 65/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0587 - acc: 0.9784\n",
      "Epoch 66/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0558 - acc: 0.9792\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49508/49508 [==============================] - 6s 118us/step - loss: 0.0488 - acc: 0.9821\n",
      "Epoch 68/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0544 - acc: 0.9795\n",
      "Epoch 69/100\n",
      "49508/49508 [==============================] - 6s 120us/step - loss: 0.0530 - acc: 0.9809\n",
      "Epoch 70/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0542 - acc: 0.9802\n",
      "Epoch 71/100\n",
      "49508/49508 [==============================] - 6s 122us/step - loss: 0.0507 - acc: 0.9820\n",
      "Epoch 72/100\n",
      "49508/49508 [==============================] - 6s 119us/step - loss: 0.0485 - acc: 0.9822\n",
      "Epoch 73/100\n",
      "49508/49508 [==============================] - 5s 105us/step - loss: 0.0490 - acc: 0.9816\n",
      "Epoch 74/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0533 - acc: 0.9801\n",
      "Epoch 75/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0494 - acc: 0.9817\n",
      "Epoch 76/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0506 - acc: 0.9815\n",
      "Epoch 77/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0465 - acc: 0.9830\n",
      "Epoch 78/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0455 - acc: 0.9829\n",
      "Epoch 79/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0454 - acc: 0.9833\n",
      "Epoch 80/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0454 - acc: 0.9837\n",
      "Epoch 81/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0446 - acc: 0.9837\n",
      "Epoch 82/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0487 - acc: 0.9818\n",
      "Epoch 83/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0440 - acc: 0.9837\n",
      "Epoch 84/100\n",
      "49508/49508 [==============================] - 4s 86us/step - loss: 0.0468 - acc: 0.9830\n",
      "Epoch 85/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0446 - acc: 0.9842\n",
      "Epoch 86/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0455 - acc: 0.9840\n",
      "Epoch 87/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0399 - acc: 0.9861\n",
      "Epoch 88/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0410 - acc: 0.9853\n",
      "Epoch 89/100\n",
      "49508/49508 [==============================] - 4s 82us/step - loss: 0.0445 - acc: 0.9834\n",
      "Epoch 90/100\n",
      "49508/49508 [==============================] - 4s 81us/step - loss: 0.0430 - acc: 0.9846\n",
      "Epoch 91/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0410 - acc: 0.9847\n",
      "Epoch 92/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0462 - acc: 0.9832\n",
      "Epoch 93/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0410 - acc: 0.9850\n",
      "Epoch 94/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0417 - acc: 0.9847\n",
      "Epoch 95/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0372 - acc: 0.9863\n",
      "Epoch 96/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0397 - acc: 0.9855\n",
      "Epoch 97/100\n",
      "49508/49508 [==============================] - 4s 85us/step - loss: 0.0422 - acc: 0.9849\n",
      "Epoch 98/100\n",
      "49508/49508 [==============================] - 4s 83us/step - loss: 0.0391 - acc: 0.9857\n",
      "Epoch 99/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0385 - acc: 0.9861\n",
      "Epoch 100/100\n",
      "49508/49508 [==============================] - 4s 84us/step - loss: 0.0387 - acc: 0.9860\n",
      "Epoch 1/100\n",
      "49510/49510 [==============================] - 11s 226us/step - loss: 0.5975 - acc: 0.6779\n",
      "Epoch 2/100\n",
      "49510/49510 [==============================] - 6s 124us/step - loss: 0.5281 - acc: 0.7339 0s - loss: 0.527\n",
      "Epoch 3/100\n",
      "49510/49510 [==============================] - 6s 118us/step - loss: 0.4915 - acc: 0.7567\n",
      "Epoch 4/100\n",
      "49510/49510 [==============================] - 6s 116us/step - loss: 0.4607 - acc: 0.7778\n",
      "Epoch 5/100\n",
      "49510/49510 [==============================] - 6s 121us/step - loss: 0.4318 - acc: 0.7952\n",
      "Epoch 6/100\n",
      "49510/49510 [==============================] - 6s 116us/step - loss: 0.4003 - acc: 0.8140\n",
      "Epoch 7/100\n",
      "49510/49510 [==============================] - 6s 124us/step - loss: 0.3776 - acc: 0.8280\n",
      "Epoch 8/100\n",
      "49510/49510 [==============================] - 6s 119us/step - loss: 0.3488 - acc: 0.8435\n",
      "Epoch 9/100\n",
      "49510/49510 [==============================] - 6s 122us/step - loss: 0.3248 - acc: 0.8572\n",
      "Epoch 10/100\n",
      "49510/49510 [==============================] - 6s 127us/step - loss: 0.2933 - acc: 0.8734 - ETA: 0s - loss: 0.2918 - acc: 0\n",
      "Epoch 11/100\n",
      "49510/49510 [==============================] - 6s 124us/step - loss: 0.2721 - acc: 0.8852\n",
      "Epoch 12/100\n",
      "49510/49510 [==============================] - 6s 118us/step - loss: 0.2613 - acc: 0.8918\n",
      "Epoch 13/100\n",
      "49510/49510 [==============================] - 6s 127us/step - loss: 0.2406 - acc: 0.8998\n",
      "Epoch 14/100\n",
      "49510/49510 [==============================] - 6s 120us/step - loss: 0.2196 - acc: 0.9087\n",
      "Epoch 15/100\n",
      "49510/49510 [==============================] - 6s 119us/step - loss: 0.2069 - acc: 0.9152\n",
      "Epoch 16/100\n",
      "49510/49510 [==============================] - 6s 121us/step - loss: 0.1890 - acc: 0.9220 0s - loss: 0.\n",
      "Epoch 17/100\n",
      "49510/49510 [==============================] - 6s 127us/step - loss: 0.1768 - acc: 0.9292\n",
      "Epoch 18/100\n",
      "49510/49510 [==============================] - 6s 124us/step - loss: 0.1672 - acc: 0.9329\n",
      "Epoch 19/100\n",
      "49510/49510 [==============================] - 6s 125us/step - loss: 0.1604 - acc: 0.9370\n",
      "Epoch 20/100\n",
      "49510/49510 [==============================] - 7s 134us/step - loss: 0.1488 - acc: 0.9411\n",
      "Epoch 21/100\n",
      "49510/49510 [==============================] - 6s 126us/step - loss: 0.1427 - acc: 0.9439\n",
      "Epoch 22/100\n",
      "49510/49510 [==============================] - 6s 131us/step - loss: 0.1351 - acc: 0.9474\n",
      "Epoch 23/100\n",
      "49510/49510 [==============================] - 5s 111us/step - loss: 0.1291 - acc: 0.9492\n",
      "Epoch 24/100\n",
      "49510/49510 [==============================] - 5s 99us/step - loss: 0.1187 - acc: 0.9543\n",
      "Epoch 25/100\n",
      "49510/49510 [==============================] - 4s 83us/step - loss: 0.1190 - acc: 0.9537\n",
      "Epoch 26/100\n",
      "49510/49510 [==============================] - 4s 86us/step - loss: 0.1151 - acc: 0.9553: 0s - loss: 0.1116\n",
      "Epoch 27/100\n",
      "49510/49510 [==============================] - 4s 85us/step - loss: 0.1131 - acc: 0.9560\n",
      "Epoch 28/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.1077 - acc: 0.9589\n",
      "Epoch 29/100\n",
      "49510/49510 [==============================] - 4s 81us/step - loss: 0.1081 - acc: 0.9584\n",
      "Epoch 30/100\n",
      "49510/49510 [==============================] - 4s 82us/step - loss: 0.1014 - acc: 0.9599\n",
      "Epoch 31/100\n",
      "49510/49510 [==============================] - 4s 82us/step - loss: 0.1008 - acc: 0.9618\n",
      "Epoch 32/100\n",
      "49510/49510 [==============================] - 4s 83us/step - loss: 0.0959 - acc: 0.9636\n",
      "Epoch 33/100\n",
      "49510/49510 [==============================] - 4s 82us/step - loss: 0.0901 - acc: 0.9653\n",
      "Epoch 34/100\n",
      "49510/49510 [==============================] - 4s 82us/step - loss: 0.0951 - acc: 0.9642\n",
      "Epoch 35/100\n",
      "49510/49510 [==============================] - 4s 81us/step - loss: 0.0858 - acc: 0.9672\n",
      "Epoch 36/100\n",
      "49510/49510 [==============================] - 4s 81us/step - loss: 0.0887 - acc: 0.9658\n",
      "Epoch 37/100\n",
      "49510/49510 [==============================] - 4s 82us/step - loss: 0.0856 - acc: 0.9670: 1s - loss: 0\n",
      "Epoch 38/100\n",
      "49510/49510 [==============================] - 4s 83us/step - loss: 0.0874 - acc: 0.9668\n",
      "Epoch 39/100\n",
      "49510/49510 [==============================] - 4s 81us/step - loss: 0.0761 - acc: 0.9713\n",
      "Epoch 40/100\n",
      "49510/49510 [==============================] - 4s 81us/step - loss: 0.0792 - acc: 0.9709\n",
      "Epoch 41/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.0763 - acc: 0.9714\n",
      "Epoch 42/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.0791 - acc: 0.9697\n",
      "Epoch 43/100\n",
      "49510/49510 [==============================] - 4s 81us/step - loss: 0.0761 - acc: 0.9708\n",
      "Epoch 44/100\n",
      "49510/49510 [==============================] - 4s 83us/step - loss: 0.0765 - acc: 0.9707\n",
      "Epoch 45/100\n",
      "49510/49510 [==============================] - 4s 86us/step - loss: 0.0759 - acc: 0.9714: 1s - loss: 0.\n",
      "Epoch 46/100\n",
      "49510/49510 [==============================] - 4s 82us/step - loss: 0.0676 - acc: 0.9745\n",
      "Epoch 47/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.0676 - acc: 0.9750\n",
      "Epoch 48/100\n",
      "49510/49510 [==============================] - 4s 85us/step - loss: 0.0707 - acc: 0.9734\n",
      "Epoch 49/100\n",
      "49510/49510 [==============================] - 4s 88us/step - loss: 0.0654 - acc: 0.9758\n",
      "Epoch 50/100\n",
      "49510/49510 [==============================] - 4s 86us/step - loss: 0.0645 - acc: 0.9758\n",
      "Epoch 51/100\n",
      "49510/49510 [==============================] - 4s 86us/step - loss: 0.0663 - acc: 0.9753\n",
      "Epoch 52/100\n",
      "49510/49510 [==============================] - 4s 85us/step - loss: 0.0647 - acc: 0.9756\n",
      "Epoch 53/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.0623 - acc: 0.9769\n",
      "Epoch 54/100\n",
      "49510/49510 [==============================] - 4s 86us/step - loss: 0.0610 - acc: 0.9766\n",
      "Epoch 55/100\n",
      "49510/49510 [==============================] - 4s 85us/step - loss: 0.0643 - acc: 0.9758\n",
      "Epoch 56/100\n",
      "49510/49510 [==============================] - 4s 89us/step - loss: 0.0578 - acc: 0.9790\n",
      "Epoch 57/100\n",
      "49510/49510 [==============================] - 4s 86us/step - loss: 0.0589 - acc: 0.9778\n",
      "Epoch 58/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.0613 - acc: 0.9766\n",
      "Epoch 59/100\n",
      "49510/49510 [==============================] - 4s 83us/step - loss: 0.0560 - acc: 0.9794\n",
      "Epoch 60/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.0572 - acc: 0.9779\n",
      "Epoch 61/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.0570 - acc: 0.9791\n",
      "Epoch 62/100\n",
      "49510/49510 [==============================] - 4s 89us/step - loss: 0.0580 - acc: 0.9789\n",
      "Epoch 63/100\n",
      "49510/49510 [==============================] - 4s 86us/step - loss: 0.0520 - acc: 0.9809\n",
      "Epoch 64/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.0553 - acc: 0.9799\n",
      "Epoch 65/100\n",
      "49510/49510 [==============================] - 4s 84us/step - loss: 0.0538 - acc: 0.9799\n",
      "Epoch 66/100\n",
      "49510/49510 [==============================] - 4s 86us/step - loss: 0.0547 - acc: 0.9805\n",
      "Epoch 67/100\n",
      "49510/49510 [==============================] - 4s 87us/step - loss: 0.0558 - acc: 0.9790\n",
      "Epoch 68/100\n",
      "49510/49510 [==============================] - 4s 83us/step - loss: 0.0491 - acc: 0.9814\n",
      "Epoch 69/100\n",
      "49510/49510 [==============================] - 4s 88us/step - loss: 0.0522 - acc: 0.9809\n",
      "Epoch 70/100\n",
      "49510/49510 [==============================] - 5s 93us/step - loss: 0.0473 - acc: 0.9823\n",
      "Epoch 71/100\n",
      "49510/49510 [==============================] - 4s 81us/step - loss: 0.0531 - acc: 0.9800\n",
      "Epoch 72/100\n",
      "49510/49510 [==============================] - 4s 81us/step - loss: 0.0453 - acc: 0.9836\n",
      "Epoch 73/100\n",
      "49510/49510 [==============================] - 5s 91us/step - loss: 0.0491 - acc: 0.9813\n",
      "Epoch 74/100\n",
      "49510/49510 [==============================] - 4s 89us/step - loss: 0.0523 - acc: 0.9805\n",
      "Epoch 75/100\n",
      "49510/49510 [==============================] - 4s 89us/step - loss: 0.0491 - acc: 0.9817\n",
      "Epoch 76/100\n",
      "49510/49510 [==============================] - 5s 103us/step - loss: 0.0456 - acc: 0.9842\n",
      "Epoch 77/100\n",
      "49510/49510 [==============================] - 4s 89us/step - loss: 0.0438 - acc: 0.9844\n",
      "Epoch 78/100\n",
      "49510/49510 [==============================] - 4s 85us/step - loss: 0.0510 - acc: 0.9816\n",
      "Epoch 79/100\n",
      "49510/49510 [==============================] - 4s 89us/step - loss: 0.0476 - acc: 0.9829\n",
      "Epoch 80/100\n",
      "49510/49510 [==============================] - 5s 92us/step - loss: 0.0464 - acc: 0.9832\n",
      "Epoch 81/100\n",
      "49510/49510 [==============================] - 4s 82us/step - loss: 0.0448 - acc: 0.9836\n",
      "Epoch 82/100\n",
      "49510/49510 [==============================] - 4s 81us/step - loss: 0.0418 - acc: 0.9837\n",
      "Epoch 83/100\n",
      "49510/49510 [==============================] - 4s 85us/step - loss: 0.0461 - acc: 0.9831\n",
      "Epoch 84/100\n",
      "49510/49510 [==============================] - 5s 93us/step - loss: 0.0426 - acc: 0.9839\n",
      "Epoch 85/100\n",
      "49510/49510 [==============================] - 5s 109us/step - loss: 0.0443 - acc: 0.9840\n",
      "Epoch 86/100\n",
      "49510/49510 [==============================] - 4s 90us/step - loss: 0.0488 - acc: 0.9821\n",
      "Epoch 87/100\n",
      "49510/49510 [==============================] - 4s 90us/step - loss: 0.0385 - acc: 0.9861\n",
      "Epoch 88/100\n",
      "49510/49510 [==============================] - 5s 92us/step - loss: 0.0423 - acc: 0.9847\n",
      "Epoch 89/100\n",
      "49510/49510 [==============================] - 4s 85us/step - loss: 0.0445 - acc: 0.9841\n",
      "Epoch 90/100\n",
      "49510/49510 [==============================] - 4s 85us/step - loss: 0.0393 - acc: 0.9859\n",
      "Epoch 91/100\n",
      "49510/49510 [==============================] - 4s 87us/step - loss: 0.0435 - acc: 0.9844\n",
      "Epoch 92/100\n",
      "49510/49510 [==============================] - 4s 85us/step - loss: 0.0436 - acc: 0.9842\n",
      "Epoch 93/100\n",
      "49510/49510 [==============================] - 4s 83us/step - loss: 0.0398 - acc: 0.9857\n",
      "Epoch 94/100\n",
      "49510/49510 [==============================] - 4s 87us/step - loss: 0.0400 - acc: 0.9854\n",
      "Epoch 95/100\n",
      "49510/49510 [==============================] - 4s 90us/step - loss: 0.0425 - acc: 0.9846\n",
      "Epoch 96/100\n",
      "49510/49510 [==============================] - 4s 86us/step - loss: 0.0356 - acc: 0.9876\n",
      "Epoch 97/100\n",
      "49510/49510 [==============================] - 5s 93us/step - loss: 0.0391 - acc: 0.9853\n",
      "Epoch 98/100\n",
      "49510/49510 [==============================] - 6s 121us/step - loss: 0.0395 - acc: 0.9857\n",
      "Epoch 99/100\n",
      "49510/49510 [==============================] - 7s 132us/step - loss: 0.0414 - acc: 0.9850\n",
      "Epoch 100/100\n",
      " 5880/49510 [==>...........................] - ETA: 5s - loss: 0.0439 - acc: 0.9823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-23-bbd2ec1e2039>\", line 40, in <module>\n",
      "    model.fit(x_train, y_train, epochs=100, batch_size=120)\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\keras\\models.py\", line 963, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\", line 1705, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\", line 1221, in _fit_loop\n",
      "    ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\", line 385, in _slice_arrays\n",
      "    return [None if x is None else x[start] for x in arrays]\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\", line 385, in <listcomp>\n",
      "    return [None if x is None else x[start] for x in arrays]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"c:\\users\\msros\\anaconda22\\envs\\py36\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "input_neurons=int(X.shape[1])\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "cvscores = []\n",
    "cv1scores = []\n",
    "cv2scores = []\n",
    "cv3scores= []\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "for i, (train, test) in enumerate(kfold.split(X,Y)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_neurons,input_dim=input_neurons, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # oversampling\n",
    "    sm = SMOTE()\n",
    "    x_train, y_train = sm.fit_sample(X[train], Y[train])\n",
    "    #Evaluate the Model\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=120)\n",
    "    y_pred=model.predict(X[test])\n",
    "    y_pred = np.where(y_pred>0.5,1,0)\n",
    "    cvscores.append(metrics.precision_score(Y[test], y_pred,average='binary'))\n",
    "    cv1scores.append(metrics.recall_score(Y[test], y_pred,average='binary'))\n",
    "    cv2scores.append(metrics.f1_score(Y[test], y_pred,average='binary'))\n",
    "    cv3scores.append(metrics.roc_auc_score(Y[test], y_pred))\n",
    "    \n",
    "\n",
    "\n",
    "print ('precision score: %.3f' % np.mean(cvscores))\n",
    "print ('recall score: %.3f' % np.mean(cv1scores))\n",
    "print ('f1 score: %.3f' % np.mean(cv2scores))\n",
    "print ('auc roc score: %.3f' % np.mean(cv3scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Random Forest, Logistic Regression and Keras Model into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and write the Random Forest model\n",
    "rfmodel_pkl = open('rfmodel.pkl', 'wb')\n",
    "pickle.dump(RF_model, rfmodel_pkl)\n",
    "rfmodel_pkl.close()\n",
    "\n",
    "#Save and write the Logistic Regression model\n",
    "lrmodel_pkl = open('lrmodel.pkl', 'wb')\n",
    "pickle.dump(logreg, lrmodel_pkl)\n",
    "lrmodel_pkl.close()\n",
    "\n",
    "#Save and write the Deep Learning model\n",
    "model.save('dlmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Random Forest\n",
    "rfmodel_pkl = open('rfmodel.pkl', 'rb')\n",
    "clf1_rf = pickle.load(rfmodel_pkl)\n",
    "y_pred_clf1 = clf1_rf.predict_proba(x_test)\n",
    "y_pred_1 = np.array(y_pred_clf1)\n",
    "y_pred_1 = np.delete(y_pred_1,np.s_[:1],1)\n",
    "\n",
    "#Load Logistic Regression\n",
    "lrmodel_pkl = open('lrmodel.pkl', 'rb')\n",
    "clf2_lr = pickle.load(lrmodel_pkl)\n",
    "y_pred_clf2 = clf2_lr.predict_proba(x_test)\n",
    "y_pred_2 = np.array(y_pred_clf2)\n",
    "y_pred_2 = np.delete(y_pred_2,np.s_[:1],1)\n",
    "\n",
    "#Load Deep Learning Model\n",
    "clf3_dl = load_model('dlmodel.h5')\n",
    "y_pred_3=clf3_dl.predict(x_test)\n",
    "y_pred_3 = np.array(y_pred_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_arr = np.concatenate((y_pred_1,y_pred_2,y_pred_3),axis=1)\n",
    "ens_arr = np.mean(ens_arr,axis=1)\n",
    "pred_ens = np.where(ens_arr>0.5,1,0)\n",
    "print ('Accuracy score: %.3f' % metrics.accuracy_score(y_test, pred_ens))\n",
    "print('precision score: %.3f' % metrics.precision_score(y_test, pred_ens))\n",
    "print('recall score: %.3f' % metrics.recall_score(y_test, pred_ens))\n",
    "print('f1 score: %.3f' % metrics.f1_score(y_test,pred_ens))\n",
    "print ('roc_auc score: %.3f' % metrics.roc_auc_score(y_test, pred_ens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
